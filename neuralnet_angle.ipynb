{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2ec2f4",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "8392002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "1a3f2b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n",
      "3.0.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc26703",
   "metadata": {},
   "source": [
    "## Define global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "1ee56892",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_OPTIMIZER = \"SGD\"\n",
    "MY_EPOCHS = 200\n",
    "#MY_LEARNING_RATE = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf698e1",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "e284cb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2151, 8)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maneuvers = pd.read_csv(\"maneuvers.csv\")\n",
    "#maneuvers.head()\n",
    "maneuvers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "d8d29c78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>dz</th>\n",
       "      <th>dv_st</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2151.000000</td>\n",
       "      <td>2151.000000</td>\n",
       "      <td>2.151000e+03</td>\n",
       "      <td>2151.000000</td>\n",
       "      <td>2.151000e+03</td>\n",
       "      <td>2151.000000</td>\n",
       "      <td>2.151000e+03</td>\n",
       "      <td>2.151000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7536.957546</td>\n",
       "      <td>-0.990424</td>\n",
       "      <td>6.175903e-07</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>2.431095e-07</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-2.994140e-07</td>\n",
       "      <td>7.474111e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4354.500254</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>3.211219e-03</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>2.138460e-03</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>1.451511e-03</td>\n",
       "      <td>1.078893e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.991665</td>\n",
       "      <td>-4.520937e-03</td>\n",
       "      <td>-0.001121</td>\n",
       "      <td>-3.245119e-03</td>\n",
       "      <td>-0.009033</td>\n",
       "      <td>-2.050332e-03</td>\n",
       "      <td>-1.181526e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3768.478500</td>\n",
       "      <td>-0.991457</td>\n",
       "      <td>-3.216103e-03</td>\n",
       "      <td>-0.000860</td>\n",
       "      <td>-1.976982e-03</td>\n",
       "      <td>-0.006508</td>\n",
       "      <td>-1.466374e-03</td>\n",
       "      <td>-9.900478e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7536.958000</td>\n",
       "      <td>-0.990588</td>\n",
       "      <td>1.015676e-05</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>2.367661e-06</td>\n",
       "      <td>-0.000377</td>\n",
       "      <td>-5.864952e-06</td>\n",
       "      <td>4.617278e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11305.435000</td>\n",
       "      <td>-0.989402</td>\n",
       "      <td>3.221367e-03</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>1.975589e-03</td>\n",
       "      <td>0.006449</td>\n",
       "      <td>1.464506e-03</td>\n",
       "      <td>1.594209e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15073.920000</td>\n",
       "      <td>-0.988842</td>\n",
       "      <td>4.520490e-03</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>3.245231e-03</td>\n",
       "      <td>0.009929</td>\n",
       "      <td>2.048730e-03</td>\n",
       "      <td>3.558238e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  t            x             y            z            dx  \\\n",
       "count   2151.000000  2151.000000  2.151000e+03  2151.000000  2.151000e+03   \n",
       "mean    7536.957546    -0.990424  6.175903e-07    -0.000165  2.431095e-07   \n",
       "std     4354.500254     0.001020  3.211219e-03     0.000703  2.138460e-03   \n",
       "min        0.000000    -0.991665 -4.520937e-03    -0.001121 -3.245119e-03   \n",
       "25%     3768.478500    -0.991457 -3.216103e-03    -0.000860 -1.976982e-03   \n",
       "50%     7536.958000    -0.990588  1.015676e-05    -0.000215  2.367661e-06   \n",
       "75%    11305.435000    -0.989402  3.221367e-03     0.000531  1.975589e-03   \n",
       "max    15073.920000    -0.988842  4.520490e-03     0.000898  3.245231e-03   \n",
       "\n",
       "                dy            dz         dv_st  \n",
       "count  2151.000000  2.151000e+03  2.151000e+03  \n",
       "mean     -0.000005 -2.994140e-07  7.474111e-08  \n",
       "std       0.006599  1.451511e-03  1.078893e-07  \n",
       "min      -0.009033 -2.050332e-03 -1.181526e-07  \n",
       "25%      -0.006508 -1.466374e-03 -9.900478e-09  \n",
       "50%      -0.000377 -5.864952e-06  4.617278e-08  \n",
       "75%       0.006449  1.464506e-03  1.594209e-07  \n",
       "max       0.009929  2.048730e-03  3.558238e-07  "
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maneuvers.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b34847",
   "metadata": {},
   "source": [
    "## Add/Drop Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157af24d",
   "metadata": {},
   "source": [
    "Try adding new attribute \"angle\" = angle in the periodic orbit, which is essentially time/period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "5e0d4535",
   "metadata": {},
   "outputs": [],
   "source": [
    "maneuvers[\"angle\"]=maneuvers[\"t\"].apply(lambda x: math.fmod(x, 0.3059226605957322E+01))\n",
    "maneuvers = maneuvers.drop([\"t\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bee80c",
   "metadata": {},
   "source": [
    "# Prepare the Data for Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "7cbc65d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's separate the predictors and the labels\n",
    "maneuvers_predictors = maneuvers[\"angle\"].copy()\n",
    "maneuvers_predictors = maneuvers_predictors.array.reshape(-1,1)\n",
    "maneuvers_labels = maneuvers[\"dv_st\"].copy().array.reshape(-1,1)\n",
    "#maneuvers_predictors.head()\n",
    "#maneuvers_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0619848",
   "metadata": {},
   "source": [
    "## Create a Train/Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "403ea1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1290, 1)\n",
      "(431, 1)\n",
      "(430, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "maneuvers_predictors, maneuvers_labels, test_size=0.2, random_state=1)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full, random_state=2)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_valid.shape)\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "ad507e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15080491],\n",
       "       [0.72963993],\n",
       "       [0.12235957],\n",
       "       [0.72721447],\n",
       "       [0.79363744]])"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale all the features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_train = scaler.fit_transform(y_train)\n",
    "y_valid = scaler.transform(y_valid)\n",
    "y_test = scaler.transform(y_test)\n",
    "X_train_scaled[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac054552",
   "metadata": {},
   "source": [
    "# Building, Training, and Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ce2bc",
   "metadata": {},
   "source": [
    "The output layer has a single neuron (since we only want to\n",
    "predict a single value) and uses no activation function, and the loss function is the mean squared error. \n",
    "\n",
    "Since the dataset is quite noisy, we just use a single hidden layer with fewer neurons than before, to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "ee78d856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/anaconda3/envs/halo/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_22\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_67 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │           \u001b[38;5;34m600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_68 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_69 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,801</span> (120.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,801\u001b[0m (120.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,801</span> (120.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,801\u001b[0m (120.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Dense(300, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "keras.layers.Dense(100, activation=\"relu\"),\n",
    "keras.layers.Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "0a508751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1655 - val_loss: 0.1012\n",
      "Epoch 2/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1103 - val_loss: 0.0769\n",
      "Epoch 3/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0831 - val_loss: 0.0726\n",
      "Epoch 4/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0735 - val_loss: 0.0697\n",
      "Epoch 5/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0717 - val_loss: 0.0669\n",
      "Epoch 6/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0725 - val_loss: 0.0643\n",
      "Epoch 7/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0682 - val_loss: 0.0620\n",
      "Epoch 8/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0618 - val_loss: 0.0600\n",
      "Epoch 9/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0619 - val_loss: 0.0579\n",
      "Epoch 10/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0631 - val_loss: 0.0561\n",
      "Epoch 11/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0551 - val_loss: 0.0552\n",
      "Epoch 12/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0603 - val_loss: 0.0533\n",
      "Epoch 13/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0561 - val_loss: 0.0523\n",
      "Epoch 14/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0567 - val_loss: 0.0516\n",
      "Epoch 15/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0536 - val_loss: 0.0508\n",
      "Epoch 16/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0525 - val_loss: 0.0503\n",
      "Epoch 17/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0551 - val_loss: 0.0499\n",
      "Epoch 18/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0497 - val_loss: 0.0494\n",
      "Epoch 19/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0529 - val_loss: 0.0490\n",
      "Epoch 20/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0518 - val_loss: 0.0488\n",
      "Epoch 21/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0527 - val_loss: 0.0488\n",
      "Epoch 22/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0515 - val_loss: 0.0485\n",
      "Epoch 23/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0482 - val_loss: 0.0488\n",
      "Epoch 24/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0513 - val_loss: 0.0478\n",
      "Epoch 25/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0475 - val_loss: 0.0483\n",
      "Epoch 26/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0511 - val_loss: 0.0476\n",
      "Epoch 27/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0489 - val_loss: 0.0478\n",
      "Epoch 28/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0491 - val_loss: 0.0474\n",
      "Epoch 29/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0513 - val_loss: 0.0463\n",
      "Epoch 30/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0500 - val_loss: 0.0459\n",
      "Epoch 31/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0502 - val_loss: 0.0456\n",
      "Epoch 32/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0498 - val_loss: 0.0454\n",
      "Epoch 33/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0495 - val_loss: 0.0451\n",
      "Epoch 34/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0450 - val_loss: 0.0450\n",
      "Epoch 35/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0475 - val_loss: 0.0445\n",
      "Epoch 36/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0461 - val_loss: 0.0442\n",
      "Epoch 37/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0474 - val_loss: 0.0440\n",
      "Epoch 38/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0482 - val_loss: 0.0437\n",
      "Epoch 39/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0491 - val_loss: 0.0434\n",
      "Epoch 40/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0436 - val_loss: 0.0434\n",
      "Epoch 41/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0480 - val_loss: 0.0428\n",
      "Epoch 42/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0447 - val_loss: 0.0424\n",
      "Epoch 43/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0442 - val_loss: 0.0421\n",
      "Epoch 44/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0442 - val_loss: 0.0418\n",
      "Epoch 45/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0428 - val_loss: 0.0417\n",
      "Epoch 46/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0437 - val_loss: 0.0412\n",
      "Epoch 47/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0437 - val_loss: 0.0408\n",
      "Epoch 48/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0437 - val_loss: 0.0404\n",
      "Epoch 49/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0429 - val_loss: 0.0400\n",
      "Epoch 50/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0422 - val_loss: 0.0398\n",
      "Epoch 51/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0432 - val_loss: 0.0393\n",
      "Epoch 52/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0427 - val_loss: 0.0389\n",
      "Epoch 53/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0440 - val_loss: 0.0386\n",
      "Epoch 54/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0398 - val_loss: 0.0381\n",
      "Epoch 55/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0422 - val_loss: 0.0378\n",
      "Epoch 56/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0394 - val_loss: 0.0373\n",
      "Epoch 57/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0381 - val_loss: 0.0371\n",
      "Epoch 58/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0398 - val_loss: 0.0364\n",
      "Epoch 59/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - val_loss: 0.0361\n",
      "Epoch 60/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0384 - val_loss: 0.0355\n",
      "Epoch 61/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0382 - val_loss: 0.0350\n",
      "Epoch 62/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - val_loss: 0.0348\n",
      "Epoch 63/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - val_loss: 0.0341\n",
      "Epoch 64/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - val_loss: 0.0338\n",
      "Epoch 65/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - val_loss: 0.0332\n",
      "Epoch 66/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - val_loss: 0.0327\n",
      "Epoch 67/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - val_loss: 0.0325\n",
      "Epoch 68/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - val_loss: 0.0316\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0337 - val_loss: 0.0311\n",
      "Epoch 70/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0338 - val_loss: 0.0308\n",
      "Epoch 71/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0319 - val_loss: 0.0301\n",
      "Epoch 72/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0316 - val_loss: 0.0297\n",
      "Epoch 73/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0320 - val_loss: 0.0292\n",
      "Epoch 74/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0309 - val_loss: 0.0286\n",
      "Epoch 75/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0321 - val_loss: 0.0281\n",
      "Epoch 76/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0292 - val_loss: 0.0276\n",
      "Epoch 77/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0307 - val_loss: 0.0270\n",
      "Epoch 78/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0287 - val_loss: 0.0267\n",
      "Epoch 79/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0279 - val_loss: 0.0260\n",
      "Epoch 80/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0288 - val_loss: 0.0255\n",
      "Epoch 81/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0261 - val_loss: 0.0254\n",
      "Epoch 82/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0273 - val_loss: 0.0247\n",
      "Epoch 83/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0264 - val_loss: 0.0242\n",
      "Epoch 84/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0233 - val_loss: 0.0238\n",
      "Epoch 85/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0276 - val_loss: 0.0233\n",
      "Epoch 86/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0240 - val_loss: 0.0228\n",
      "Epoch 87/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0254 - val_loss: 0.0225\n",
      "Epoch 88/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0249 - val_loss: 0.0220\n",
      "Epoch 89/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0234 - val_loss: 0.0215\n",
      "Epoch 90/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0236 - val_loss: 0.0212\n",
      "Epoch 91/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0211 - val_loss: 0.0208\n",
      "Epoch 92/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0219 - val_loss: 0.0203\n",
      "Epoch 93/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0216 - val_loss: 0.0200\n",
      "Epoch 94/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0208 - val_loss: 0.0195\n",
      "Epoch 95/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0202 - val_loss: 0.0190\n",
      "Epoch 96/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0195 - val_loss: 0.0187\n",
      "Epoch 97/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0182 - val_loss: 0.0183\n",
      "Epoch 98/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0185 - val_loss: 0.0181\n",
      "Epoch 99/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 100/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0186 - val_loss: 0.0174\n",
      "Epoch 101/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0179 - val_loss: 0.0169\n",
      "Epoch 102/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0180 - val_loss: 0.0163\n",
      "Epoch 103/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0167 - val_loss: 0.0160\n",
      "Epoch 104/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0178 - val_loss: 0.0157\n",
      "Epoch 105/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0168 - val_loss: 0.0153\n",
      "Epoch 106/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - val_loss: 0.0149\n",
      "Epoch 107/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0184 - val_loss: 0.0149\n",
      "Epoch 108/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - val_loss: 0.0144\n",
      "Epoch 109/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - val_loss: 0.0139\n",
      "Epoch 110/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - val_loss: 0.0135\n",
      "Epoch 111/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - val_loss: 0.0133\n",
      "Epoch 112/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - val_loss: 0.0129\n",
      "Epoch 113/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0142 - val_loss: 0.0126\n",
      "Epoch 114/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - val_loss: 0.0124\n",
      "Epoch 115/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - val_loss: 0.0120\n",
      "Epoch 116/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 117/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 118/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 119/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 120/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - val_loss: 0.0108\n",
      "Epoch 121/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 122/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0104\n",
      "Epoch 123/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 124/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 125/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0098\n",
      "Epoch 126/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 127/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 128/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 129/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 130/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 131/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 132/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 133/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0085\n",
      "Epoch 134/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0085\n",
      "Epoch 135/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 136/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 137/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 138/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0079\n",
      "Epoch 139/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 140/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0078\n",
      "Epoch 141/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 142/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0078\n",
      "Epoch 143/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 144/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0073\n",
      "Epoch 145/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 146/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - val_loss: 0.0072\n",
      "Epoch 147/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - val_loss: 0.0070\n",
      "Epoch 148/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0069\n",
      "Epoch 149/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0069\n",
      "Epoch 150/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0067\n",
      "Epoch 151/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - val_loss: 0.0067\n",
      "Epoch 152/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 153/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0066\n",
      "Epoch 154/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 155/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 156/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 157/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 158/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 159/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 160/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0061\n",
      "Epoch 161/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 162/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 163/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 164/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 165/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 166/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 167/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 168/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 169/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 170/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 171/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 172/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 173/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 174/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 175/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 176/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 177/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 178/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 179/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 180/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 181/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 182/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 183/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 184/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 185/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 186/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 187/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 188/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 189/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 190/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 191/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 192/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 193/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 194/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 195/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 196/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 197/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 198/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 199/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 200/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0043\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=1.e-4)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=MY_EPOCHS, \n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "4df21ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curves\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "#plt.gca().set_ylim(0, 5e-5) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "eb432acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.0055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06673935831555564"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test_scaled, y_test)\n",
    "np.sqrt(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "181daa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test_scaled[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "ca87781a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25684577],\n",
       "       [0.72115753],\n",
       "       [0.94215579]])"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "8d8a8fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33966047],\n",
       "       [0.8262629 ],\n",
       "       [0.773115  ]], dtype=float32)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d0bc8",
   "metadata": {},
   "source": [
    "# Fine-Tuning Neural Network Hyperparameters\n",
    "\n",
    "Wrap our Keras models in objects that mimic regular Scikit-Learn regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e052ee1",
   "metadata": {},
   "source": [
    "def build_model(n_hidden, n_neurons, learning_rate, \n",
    "                input_shape):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", \n",
    "                                     **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, **options))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "keras_reg = KerasRegressor(build_model, n_hidden=1, n_neurons=30, learning_rate=3e-3, \n",
    "                input_shape=[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8a171888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    #model.add(layers.Flatten())\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 5)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "               # Tune number of units separately for each layer.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                activation=\"relu\",\n",
    "            )\n",
    "        )\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    #learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "\n",
    "    model.compile(\n",
    "        #optimizer=keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "        optimizer=MY_OPTIMIZER,\n",
    "        loss=\"mean_squared_error\",\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "537260cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential_3, built=False>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quickly test if model builds successfuly\n",
    "import keras_tuner\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894b3759",
   "metadata": {},
   "source": [
    "Use a randomized search to train hundreds of hyperparameter combinations  and see which one performs best on the validation set.\n",
    "\n",
    "Note that RandomizedSearchCV uses K-fold cross-validation, so it\n",
    "does not use X_valid and y_valid . These are just used for early stopping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf98fb",
   "metadata": {},
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, \n",
    "                                   n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "46016dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "04174a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# print a summary of the search space\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dac7ce",
   "metadata": {},
   "source": [
    "Then, start the search for the best hyperparameter configuration. All the arguments passed to search is passed to model.fit() in each execution. Remember to pass validation_data to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2b9dc4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 18s]\n",
      "val_loss: 3.865438547023814e-08\n",
      "\n",
      "Best val_loss So Far: 3.865438547023814e-08\n",
      "Total elapsed time: 00h 00m 18s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "3                 |2                 |num_layers\n",
      "128               |384               |units_0\n",
      "160               |32                |units_1\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.7047e-04 - val_loss: 4.8468e-05\n",
      "Epoch 2/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8071e-05 - val_loss: 3.9004e-05\n",
      "Epoch 3/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9745e-05 - val_loss: 3.2025e-05\n",
      "Epoch 4/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1950e-05 - val_loss: 2.6294e-05\n",
      "Epoch 5/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5892e-05 - val_loss: 2.1554e-05\n",
      "Epoch 6/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0937e-05 - val_loss: 1.7705e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7122e-05 - val_loss: 1.4385e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4070e-05 - val_loss: 1.1697e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1379e-05 - val_loss: 9.5272e-06\n",
      "Epoch 10/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0980e-06 - val_loss: 7.7259e-06\n",
      "Epoch 11/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4501e-06 - val_loss: 6.3038e-06\n",
      "Epoch 12/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1418e-06 - val_loss: 5.1344e-06\n",
      "Epoch 13/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1796e-06 - val_loss: 4.2146e-06\n",
      "Epoch 14/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0794e-06 - val_loss: 3.4742e-06\n",
      "Epoch 15/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3055e-06 - val_loss: 2.8729e-06\n",
      "Epoch 16/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7834e-06 - val_loss: 2.3912e-06\n",
      "Epoch 17/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2570e-06 - val_loss: 2.0027e-06\n",
      "Epoch 18/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8195e-06 - val_loss: 1.6851e-06\n",
      "Epoch 19/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5536e-06 - val_loss: 1.4314e-06\n",
      "Epoch 20/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3875e-06 - val_loss: 1.2254e-06\n",
      "Epoch 21/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1678e-06 - val_loss: 1.0560e-06\n",
      "Epoch 22/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0080e-06 - val_loss: 9.1944e-07\n",
      "Epoch 23/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0155e-07 - val_loss: 8.0405e-07\n",
      "Epoch 24/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8399e-07 - val_loss: 7.1186e-07\n",
      "Epoch 25/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0473e-07 - val_loss: 6.3415e-07\n",
      "Epoch 26/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3129e-07 - val_loss: 5.6935e-07\n",
      "Epoch 27/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8254e-07 - val_loss: 5.1614e-07\n",
      "Epoch 28/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0609e-07 - val_loss: 4.7035e-07\n",
      "Epoch 29/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5615e-07 - val_loss: 4.3202e-07\n",
      "Epoch 30/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4905e-07 - val_loss: 3.9670e-07\n",
      "Epoch 31/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0333e-07 - val_loss: 3.6805e-07\n",
      "Epoch 32/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7909e-07 - val_loss: 3.4315e-07\n",
      "Epoch 33/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7846e-07 - val_loss: 3.2001e-07\n",
      "Epoch 34/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3495e-07 - val_loss: 3.0126e-07\n",
      "Epoch 35/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2875e-07 - val_loss: 2.8283e-07\n",
      "Epoch 36/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8572e-07 - val_loss: 2.6625e-07\n",
      "Epoch 37/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8741e-07 - val_loss: 2.5138e-07\n",
      "Epoch 38/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5757e-07 - val_loss: 2.3757e-07\n",
      "Epoch 39/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5030e-07 - val_loss: 2.2528e-07\n",
      "Epoch 40/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4404e-07 - val_loss: 2.1306e-07\n",
      "Epoch 41/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3291e-07 - val_loss: 2.0281e-07\n",
      "Epoch 42/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1322e-07 - val_loss: 1.9199e-07\n",
      "Epoch 43/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9820e-07 - val_loss: 1.8294e-07\n",
      "Epoch 44/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0756e-07 - val_loss: 1.7372e-07\n",
      "Epoch 45/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7549e-07 - val_loss: 1.6493e-07\n",
      "Epoch 46/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0040e-07 - val_loss: 1.5697e-07\n",
      "Epoch 47/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6832e-07 - val_loss: 1.5007e-07\n",
      "Epoch 48/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7405e-07 - val_loss: 1.4334e-07\n",
      "Epoch 49/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5916e-07 - val_loss: 1.3571e-07\n",
      "Epoch 50/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4486e-07 - val_loss: 1.2886e-07\n",
      "Epoch 51/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5335e-07 - val_loss: 1.2347e-07\n",
      "Epoch 52/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4617e-07 - val_loss: 1.1704e-07\n",
      "Epoch 53/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3562e-07 - val_loss: 1.1142e-07\n",
      "Epoch 54/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2664e-07 - val_loss: 1.0641e-07\n",
      "Epoch 55/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2033e-07 - val_loss: 1.0136e-07\n",
      "Epoch 56/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1659e-07 - val_loss: 9.6411e-08\n",
      "Epoch 57/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2031e-07 - val_loss: 9.1904e-08\n",
      "Epoch 58/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0080e-07 - val_loss: 8.7818e-08\n",
      "Epoch 59/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0443e-07 - val_loss: 8.3796e-08\n",
      "Epoch 60/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0638e-07 - val_loss: 7.9702e-08\n",
      "Epoch 61/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4244e-08 - val_loss: 7.6036e-08\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5169e-08 - val_loss: 7.2436e-08\n",
      "Epoch 63/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6200e-08 - val_loss: 6.9023e-08\n",
      "Epoch 64/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3391e-08 - val_loss: 6.5916e-08\n",
      "Epoch 65/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8377e-08 - val_loss: 6.2673e-08\n",
      "Epoch 66/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2118e-08 - val_loss: 6.0079e-08\n",
      "Epoch 67/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2531e-08 - val_loss: 5.6940e-08\n",
      "Epoch 68/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.5948e-08 - val_loss: 5.4096e-08\n",
      "Epoch 69/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0508e-08 - val_loss: 5.1331e-08\n",
      "Epoch 70/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6913e-08 - val_loss: 4.8870e-08\n",
      "Epoch 71/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5265e-08 - val_loss: 4.5875e-08\n",
      "Epoch 72/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3121e-08 - val_loss: 4.3462e-08\n",
      "Epoch 73/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7577e-08 - val_loss: 4.1011e-08\n",
      "Epoch 74/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3187e-08 - val_loss: 3.9107e-08\n",
      "Epoch 75/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6631e-08 - val_loss: 3.6747e-08\n",
      "Epoch 76/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2628e-08 - val_loss: 3.4813e-08\n",
      "Epoch 77/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6128e-08 - val_loss: 3.2948e-08\n",
      "Epoch 78/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8652e-08 - val_loss: 3.1196e-08\n",
      "Epoch 79/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8023e-08 - val_loss: 2.9617e-08\n",
      "Epoch 80/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4533e-08 - val_loss: 2.7962e-08\n",
      "Epoch 81/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4907e-08 - val_loss: 2.6456e-08\n",
      "Epoch 82/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2012e-08 - val_loss: 2.5097e-08\n",
      "Epoch 83/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7591e-08 - val_loss: 2.3807e-08\n",
      "Epoch 84/100\n",
      "\u001b[1m 1/41\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.3637e-08"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch(X_train_scaled, y_train, epochs\u001b[38;5;241m=\u001b[39mMY_EPOCHS, validation_data\u001b[38;5;241m=\u001b[39m(X_valid_scaled, y_valid))\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:323\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 323\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    325\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(X_train_scaled, y_train, epochs=MY_EPOCHS, validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d5b759",
   "metadata": {},
   "source": [
    "## Query the results\n",
    "When search is over, you can retrieve the best model(s). The model is saved at its best performing epoch evaluated on the validation_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d995384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse_test = best_model.evaluate(X_test_scaled, y_test)\n",
    "np.sqrt(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9226c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test_scaled[:3] # pretend these are new instances\n",
    "y_pred = best_model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b7814",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc967704",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04410338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:halo]",
   "language": "python",
   "name": "conda-env-halo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
