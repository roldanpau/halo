{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2ec2f4",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "8392002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "1a3f2b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n",
      "3.0.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc26703",
   "metadata": {},
   "source": [
    "## Define global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "1ee56892",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_OPTIMIZER = \"Adam\"\n",
    "MY_EPOCHS = 25\n",
    "#MY_LEARNING_RATE = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf698e1",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "e284cb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4302, 8)"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maneuvers = pd.read_csv(\"maneuvers.csv\")\n",
    "#maneuvers.head()\n",
    "maneuvers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "d8d29c78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>dz</th>\n",
       "      <th>dv_st</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4302.000000</td>\n",
       "      <td>4302.000000</td>\n",
       "      <td>4.302000e+03</td>\n",
       "      <td>4302.000000</td>\n",
       "      <td>4.302000e+03</td>\n",
       "      <td>4.302000e+03</td>\n",
       "      <td>4.302000e+03</td>\n",
       "      <td>4.302000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15077.420656</td>\n",
       "      <td>-0.990424</td>\n",
       "      <td>8.529671e-07</td>\n",
       "      <td>-0.000163</td>\n",
       "      <td>6.164475e-07</td>\n",
       "      <td>-1.994053e-07</td>\n",
       "      <td>-3.525164e-07</td>\n",
       "      <td>5.085951e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8707.988721</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>3.209865e-03</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>2.137216e-03</td>\n",
       "      <td>6.596556e-03</td>\n",
       "      <td>1.443063e-03</td>\n",
       "      <td>9.891317e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.991665</td>\n",
       "      <td>-4.521035e-03</td>\n",
       "      <td>-0.001121</td>\n",
       "      <td>-3.245196e-03</td>\n",
       "      <td>-9.033096e-03</td>\n",
       "      <td>-2.050685e-03</td>\n",
       "      <td>-1.730357e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7538.710750</td>\n",
       "      <td>-0.991455</td>\n",
       "      <td>-3.225498e-03</td>\n",
       "      <td>-0.000857</td>\n",
       "      <td>-1.975802e-03</td>\n",
       "      <td>-6.507502e-03</td>\n",
       "      <td>-1.456351e-03</td>\n",
       "      <td>-2.319600e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15077.425000</td>\n",
       "      <td>-0.990587</td>\n",
       "      <td>1.051673e-06</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>2.510054e-07</td>\n",
       "      <td>-3.764976e-04</td>\n",
       "      <td>-2.211053e-07</td>\n",
       "      <td>3.250598e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22616.127500</td>\n",
       "      <td>-0.989402</td>\n",
       "      <td>3.226142e-03</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>1.980218e-03</td>\n",
       "      <td>6.442375e-03</td>\n",
       "      <td>1.454106e-03</td>\n",
       "      <td>1.172658e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30154.840000</td>\n",
       "      <td>-0.988842</td>\n",
       "      <td>4.520552e-03</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>3.245292e-03</td>\n",
       "      <td>9.929594e-03</td>\n",
       "      <td>2.049619e-03</td>\n",
       "      <td>3.585011e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  t            x             y            z            dx  \\\n",
       "count   4302.000000  4302.000000  4.302000e+03  4302.000000  4.302000e+03   \n",
       "mean   15077.420656    -0.990424  8.529671e-07    -0.000163  6.164475e-07   \n",
       "std     8707.988721     0.001019  3.209865e-03     0.000699  2.137216e-03   \n",
       "min        0.000000    -0.991665 -4.521035e-03    -0.001121 -3.245196e-03   \n",
       "25%     7538.710750    -0.991455 -3.225498e-03    -0.000857 -1.975802e-03   \n",
       "50%    15077.425000    -0.990587  1.051673e-06    -0.000213  2.510054e-07   \n",
       "75%    22616.127500    -0.989402  3.226142e-03     0.000527  1.980218e-03   \n",
       "max    30154.840000    -0.988842  4.520552e-03     0.000898  3.245292e-03   \n",
       "\n",
       "                 dy            dz         dv_st  \n",
       "count  4.302000e+03  4.302000e+03  4.302000e+03  \n",
       "mean  -1.994053e-07 -3.525164e-07  5.085951e-08  \n",
       "std    6.596556e-03  1.443063e-03  9.891317e-08  \n",
       "min   -9.033096e-03 -2.050685e-03 -1.730357e-07  \n",
       "25%   -6.507502e-03 -1.456351e-03 -2.319600e-08  \n",
       "50%   -3.764976e-04 -2.211053e-07  3.250598e-08  \n",
       "75%    6.442375e-03  1.454106e-03  1.172658e-07  \n",
       "max    9.929594e-03  2.049619e-03  3.585011e-07  "
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maneuvers.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b34847",
   "metadata": {},
   "source": [
    "## Add/Drop Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157af24d",
   "metadata": {},
   "source": [
    "Try adding new attribute \"angle\" = angle in the periodic orbit, which is essentially time/period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "5e0d4535",
   "metadata": {},
   "outputs": [],
   "source": [
    "maneuvers[\"angle\"]=maneuvers[\"t\"].apply(lambda x: math.fmod(x, 0.3059226605957322E+01))\n",
    "maneuvers = maneuvers.drop([\"t\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bee80c",
   "metadata": {},
   "source": [
    "# Prepare the Data for Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "7cbc65d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>dz</th>\n",
       "      <th>angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.990182</td>\n",
       "      <td>0.004321</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>-0.002665</td>\n",
       "      <td>-0.001851</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.989104</td>\n",
       "      <td>-0.002210</td>\n",
       "      <td>-0.001006</td>\n",
       "      <td>-0.001970</td>\n",
       "      <td>-0.007873</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.892670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.991459</td>\n",
       "      <td>-0.003319</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>-0.001307</td>\n",
       "      <td>0.006469</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.785344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.991244</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>-0.001958</td>\n",
       "      <td>2.678010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.988908</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>-0.001093</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>-0.008749</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>0.511451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y         z        dx        dy        dz     angle\n",
       "0 -0.990182  0.004321 -0.000465  0.003244 -0.002665 -0.001851  0.000000\n",
       "1 -0.989104 -0.002210 -0.001006 -0.001970 -0.007873  0.000886  0.892670\n",
       "2 -0.991459 -0.003319  0.000537 -0.001307  0.006469  0.001700  1.785344\n",
       "3 -0.991244  0.004022  0.000297  0.001999  0.004270 -0.001958  2.678010\n",
       "4 -0.988908  0.001122 -0.001093  0.001023 -0.008749 -0.000446  0.511451"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's separate the predictors and the labels\n",
    "maneuvers_predictors = maneuvers.drop(\"dv_st\", axis=1)\n",
    "maneuvers_labels = maneuvers[\"dv_st\"].copy()\n",
    "maneuvers_predictors.head()\n",
    "#maneuvers_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0619848",
   "metadata": {},
   "source": [
    "## Create a Train/Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "403ea1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2580, 7)\n",
      "(861, 7)\n",
      "(861, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>dz</th>\n",
       "      <th>angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>-0.990638</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.001974</td>\n",
       "      <td>0.034530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>-0.990552</td>\n",
       "      <td>0.004508</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>-0.000584</td>\n",
       "      <td>-0.001971</td>\n",
       "      <td>3.019119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>-0.989530</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>-0.000796</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>-0.005906</td>\n",
       "      <td>-0.001382</td>\n",
       "      <td>0.258510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>-0.991607</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.008684</td>\n",
       "      <td>-0.001101</td>\n",
       "      <td>2.456939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>-0.990007</td>\n",
       "      <td>-0.004149</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.003562</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>1.423640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             x         y         z        dx        dy        dz     angle\n",
       "3619 -0.990638  0.004516 -0.000178  0.003011 -0.000067 -0.001974  0.034530\n",
       "2488 -0.990552  0.004508 -0.000236  0.003085 -0.000584 -0.001971  3.019119\n",
       "1940 -0.989530  0.003415 -0.000796  0.002875 -0.005906 -0.001382  0.258510\n",
       "2340 -0.991607  0.002063  0.000762  0.000569  0.008684 -0.001101  2.456939\n",
       "3929 -0.990007 -0.004149 -0.000546 -0.003226 -0.003562  0.001713  1.423640"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "maneuvers_predictors, maneuvers_labels, test_size=0.2, random_state=1)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_valid.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "ad507e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36383929, 0.99958675, 0.46684884, 0.96388315, 0.47280692,\n",
       "        0.01840629, 0.01129136],\n",
       "       [0.39402636, 0.99871722, 0.43848401, 0.97533699, 0.44558051,\n",
       "        0.01930811, 0.987251  ],\n",
       "       [0.75612954, 0.8778044 , 0.16075677, 0.94294127, 0.16489459,\n",
       "        0.16284499, 0.08453265],\n",
       "       [0.02037273, 0.72831504, 0.93254659, 0.58763974, 0.93429176,\n",
       "        0.23134923, 0.80341814],\n",
       "       [0.58733702, 0.04113553, 0.28461863, 0.00292428, 0.28849762,\n",
       "        0.91781887, 0.46552977]])"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale all the features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac054552",
   "metadata": {},
   "source": [
    "# Building, Training, and Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ce2bc",
   "metadata": {},
   "source": [
    "The output layer has a single neuron (since we only want to\n",
    "predict a single value) and uses no activation function, and the loss function is the mean squared error. \n",
    "\n",
    "Since the dataset is quite noisy, we just use a single hidden layer with fewer neurons than before, to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "ee78d856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/anaconda3/envs/halo/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │         \u001b[38;5;34m2,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,601</span> (127.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,601\u001b[0m (127.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,601</span> (127.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,601\u001b[0m (127.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Dense(300, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "keras.layers.Dense(100, activation=\"relu\"),\n",
    "keras.layers.Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "c139b9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 8.3537e-04\n",
      "Epoch 2/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.3321e-04 - val_loss: 1.9579e-04\n",
      "Epoch 3/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5744e-04 - val_loss: 8.1828e-05\n",
      "Epoch 4/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6518e-05 - val_loss: 5.0877e-05\n",
      "Epoch 5/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8831e-05 - val_loss: 3.8162e-05\n",
      "Epoch 6/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9948e-05 - val_loss: 3.1392e-05\n",
      "Epoch 7/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.0495e-05 - val_loss: 2.7194e-05\n",
      "Epoch 8/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6698e-05 - val_loss: 2.3948e-05\n",
      "Epoch 9/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4194e-05 - val_loss: 2.1568e-05\n",
      "Epoch 10/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2962e-05 - val_loss: 1.9613e-05\n",
      "Epoch 11/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9295e-05 - val_loss: 1.8013e-05\n",
      "Epoch 12/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6548e-05 - val_loss: 1.6623e-05\n",
      "Epoch 13/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7197e-05 - val_loss: 1.5398e-05\n",
      "Epoch 14/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6177e-05 - val_loss: 1.4337e-05\n",
      "Epoch 15/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4190e-05 - val_loss: 1.3395e-05\n",
      "Epoch 16/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4194e-05 - val_loss: 1.2580e-05\n",
      "Epoch 17/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1260e-05 - val_loss: 1.1867e-05\n",
      "Epoch 18/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1118e-05 - val_loss: 1.1164e-05\n",
      "Epoch 19/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1078e-05 - val_loss: 1.0587e-05\n",
      "Epoch 20/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0240e-05 - val_loss: 1.0088e-05\n",
      "Epoch 21/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.1181e-06 - val_loss: 9.5177e-06\n",
      "Epoch 22/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0865e-05 - val_loss: 9.0302e-06\n",
      "Epoch 23/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.4169e-06 - val_loss: 8.6255e-06\n",
      "Epoch 24/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0157e-05 - val_loss: 8.2497e-06\n",
      "Epoch 25/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.6895e-06 - val_loss: 7.9023e-06\n",
      "Epoch 26/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.6267e-06 - val_loss: 7.6040e-06\n",
      "Epoch 27/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.0825e-06 - val_loss: 7.2951e-06\n",
      "Epoch 28/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.9193e-06 - val_loss: 7.0286e-06\n",
      "Epoch 29/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4724e-06 - val_loss: 6.7829e-06\n",
      "Epoch 30/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.8364e-06 - val_loss: 6.5733e-06\n",
      "Epoch 31/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.1535e-06 - val_loss: 6.3411e-06\n",
      "Epoch 32/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.7610e-06 - val_loss: 6.1915e-06\n",
      "Epoch 33/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.5763e-06 - val_loss: 5.9701e-06\n",
      "Epoch 34/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.1151e-06 - val_loss: 5.8165e-06\n",
      "Epoch 35/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.9556e-06 - val_loss: 5.6506e-06\n",
      "Epoch 36/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.8034e-06 - val_loss: 5.4876e-06\n",
      "Epoch 37/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5815e-06 - val_loss: 5.3650e-06\n",
      "Epoch 38/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.0453e-06 - val_loss: 5.2144e-06\n",
      "Epoch 39/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6926e-06 - val_loss: 5.0722e-06\n",
      "Epoch 40/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.1569e-06 - val_loss: 4.9948e-06\n",
      "Epoch 41/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5893e-06 - val_loss: 4.8461e-06\n",
      "Epoch 42/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.9549e-06 - val_loss: 4.7497e-06\n",
      "Epoch 43/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.9229e-06 - val_loss: 4.6435e-06\n",
      "Epoch 44/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.0220e-06 - val_loss: 4.5476e-06\n",
      "Epoch 45/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.6185e-06 - val_loss: 4.4973e-06\n",
      "Epoch 46/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8404e-06 - val_loss: 4.4040e-06\n",
      "Epoch 47/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4630e-06 - val_loss: 4.2874e-06\n",
      "Epoch 48/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.3750e-06 - val_loss: 4.2279e-06\n",
      "Epoch 49/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5977e-06 - val_loss: 4.1512e-06\n",
      "Epoch 50/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1106e-06 - val_loss: 4.0924e-06\n",
      "Epoch 51/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4610e-06 - val_loss: 4.0057e-06\n",
      "Epoch 52/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8663e-06 - val_loss: 4.0161e-06\n",
      "Epoch 53/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2251e-06 - val_loss: 3.8867e-06\n",
      "Epoch 54/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1868e-06 - val_loss: 3.8458e-06\n",
      "Epoch 55/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0178e-06 - val_loss: 3.7644e-06\n",
      "Epoch 56/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0685e-06 - val_loss: 3.7057e-06\n",
      "Epoch 57/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0293e-06 - val_loss: 3.6570e-06\n",
      "Epoch 58/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7744e-06 - val_loss: 3.6127e-06\n",
      "Epoch 59/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0879e-06 - val_loss: 3.5570e-06\n",
      "Epoch 60/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0574e-06 - val_loss: 3.5083e-06\n",
      "Epoch 61/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.4654e-06 - val_loss: 3.4661e-06\n",
      "Epoch 62/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9327e-06 - val_loss: 3.4297e-06\n",
      "Epoch 63/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9112e-06 - val_loss: 3.3849e-06\n",
      "Epoch 64/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8584e-06 - val_loss: 3.3408e-06\n",
      "Epoch 65/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7460e-06 - val_loss: 3.3011e-06\n",
      "Epoch 66/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5438e-06 - val_loss: 3.2653e-06\n",
      "Epoch 67/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2879e-06 - val_loss: 3.2356e-06\n",
      "Epoch 68/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.4131e-06 - val_loss: 3.2001e-06\n",
      "Epoch 69/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7641e-06 - val_loss: 3.1606e-06\n",
      "Epoch 70/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5395e-06 - val_loss: 3.1358e-06\n",
      "Epoch 71/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7233e-06 - val_loss: 3.0961e-06\n",
      "Epoch 72/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5793e-06 - val_loss: 3.0741e-06\n",
      "Epoch 73/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.0741e-06 - val_loss: 3.0348e-06\n",
      "Epoch 74/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.1817e-06 - val_loss: 3.0081e-06\n",
      "Epoch 75/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.9020e-06 - val_loss: 2.9863e-06\n",
      "Epoch 76/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5431e-06 - val_loss: 2.9494e-06\n",
      "Epoch 77/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.3176e-06 - val_loss: 2.9501e-06\n",
      "Epoch 78/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7941e-06 - val_loss: 2.9021e-06\n",
      "Epoch 79/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.9438e-06 - val_loss: 2.8704e-06\n",
      "Epoch 80/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.8634e-06 - val_loss: 2.8518e-06\n",
      "Epoch 81/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.8528e-06 - val_loss: 2.8468e-06\n",
      "Epoch 82/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.1756e-06 - val_loss: 2.7966e-06\n",
      "Epoch 83/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7289e-06 - val_loss: 2.7837e-06\n",
      "Epoch 84/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6724e-06 - val_loss: 2.7579e-06\n",
      "Epoch 85/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.8160e-06 - val_loss: 2.7409e-06\n",
      "Epoch 86/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.8552e-06 - val_loss: 2.7189e-06\n",
      "Epoch 87/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.8623e-06 - val_loss: 2.6870e-06\n",
      "Epoch 88/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7571e-06 - val_loss: 2.6762e-06\n",
      "Epoch 89/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.9218e-06 - val_loss: 2.6479e-06\n",
      "Epoch 90/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6042e-06 - val_loss: 2.6280e-06\n",
      "Epoch 91/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6042e-06 - val_loss: 2.6098e-06\n",
      "Epoch 92/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6291e-06 - val_loss: 2.5896e-06\n",
      "Epoch 93/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6614e-06 - val_loss: 2.5703e-06\n",
      "Epoch 94/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6389e-06 - val_loss: 2.5543e-06\n",
      "Epoch 95/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.8232e-06 - val_loss: 2.5343e-06\n",
      "Epoch 96/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3639e-06 - val_loss: 2.5125e-06\n",
      "Epoch 97/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6887e-06 - val_loss: 2.5057e-06\n",
      "Epoch 98/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5587e-06 - val_loss: 2.4910e-06\n",
      "Epoch 99/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5087e-06 - val_loss: 2.4909e-06\n",
      "Epoch 100/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5267e-06 - val_loss: 2.4523e-06\n",
      "Epoch 101/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4053e-06 - val_loss: 2.4314e-06\n",
      "Epoch 102/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3665e-06 - val_loss: 2.4180e-06\n",
      "Epoch 103/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4463e-06 - val_loss: 2.4146e-06\n",
      "Epoch 104/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3583e-06 - val_loss: 2.3815e-06\n",
      "Epoch 105/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4526e-06 - val_loss: 2.3737e-06\n",
      "Epoch 106/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5067e-06 - val_loss: 2.3528e-06\n",
      "Epoch 107/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4589e-06 - val_loss: 2.3456e-06\n",
      "Epoch 108/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4446e-06 - val_loss: 2.3217e-06\n",
      "Epoch 109/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3126e-06 - val_loss: 2.3074e-06\n",
      "Epoch 110/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2499e-06 - val_loss: 2.2975e-06\n",
      "Epoch 111/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3829e-06 - val_loss: 2.2935e-06\n",
      "Epoch 112/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2774e-06 - val_loss: 2.2708e-06\n",
      "Epoch 113/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3826e-06 - val_loss: 2.2572e-06\n",
      "Epoch 114/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2537e-06 - val_loss: 2.2438e-06\n",
      "Epoch 115/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2414e-06 - val_loss: 2.2295e-06\n",
      "Epoch 116/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1626e-06 - val_loss: 2.2262e-06\n",
      "Epoch 117/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2447e-06 - val_loss: 2.2077e-06\n",
      "Epoch 118/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2744e-06 - val_loss: 2.1968e-06\n",
      "Epoch 119/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1277e-06 - val_loss: 2.1784e-06\n",
      "Epoch 120/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1685e-06 - val_loss: 2.1761e-06\n",
      "Epoch 121/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1967e-06 - val_loss: 2.1586e-06\n",
      "Epoch 122/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2178e-06 - val_loss: 2.1432e-06\n",
      "Epoch 123/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0639e-06 - val_loss: 2.1304e-06\n",
      "Epoch 124/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0687e-06 - val_loss: 2.1186e-06\n",
      "Epoch 125/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0291e-06 - val_loss: 2.1085e-06\n",
      "Epoch 126/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0958e-06 - val_loss: 2.1050e-06\n",
      "Epoch 127/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1728e-06 - val_loss: 2.0840e-06\n",
      "Epoch 128/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2307e-06 - val_loss: 2.0854e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9437e-06 - val_loss: 2.0897e-06\n",
      "Epoch 130/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0920e-06 - val_loss: 2.0634e-06\n",
      "Epoch 131/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2389e-06 - val_loss: 2.0423e-06\n",
      "Epoch 132/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9638e-06 - val_loss: 2.0503e-06\n",
      "Epoch 133/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1778e-06 - val_loss: 2.0209e-06\n",
      "Epoch 134/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1266e-06 - val_loss: 2.0200e-06\n",
      "Epoch 135/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8599e-06 - val_loss: 2.0091e-06\n",
      "Epoch 136/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0168e-06 - val_loss: 1.9953e-06\n",
      "Epoch 137/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9186e-06 - val_loss: 1.9845e-06\n",
      "Epoch 138/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9887e-06 - val_loss: 1.9788e-06\n",
      "Epoch 139/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9607e-06 - val_loss: 1.9638e-06\n",
      "Epoch 140/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8620e-06 - val_loss: 1.9692e-06\n",
      "Epoch 141/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9895e-06 - val_loss: 1.9464e-06\n",
      "Epoch 142/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8538e-06 - val_loss: 1.9415e-06\n",
      "Epoch 143/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9628e-06 - val_loss: 1.9264e-06\n",
      "Epoch 144/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8531e-06 - val_loss: 1.9185e-06\n",
      "Epoch 145/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 1.9372e-06 - val_loss: 1.9203e-06\n",
      "Epoch 146/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0985e-06 - val_loss: 1.9016e-06\n",
      "Epoch 147/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8306e-06 - val_loss: 1.9081e-06\n",
      "Epoch 148/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8863e-06 - val_loss: 1.8886e-06\n",
      "Epoch 149/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8877e-06 - val_loss: 1.8762e-06\n",
      "Epoch 150/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7529e-06 - val_loss: 1.8681e-06\n",
      "Epoch 151/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7639e-06 - val_loss: 1.8672e-06\n",
      "Epoch 152/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8341e-06 - val_loss: 1.8519e-06\n",
      "Epoch 153/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8226e-06 - val_loss: 1.8432e-06\n",
      "Epoch 154/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7834e-06 - val_loss: 1.8352e-06\n",
      "Epoch 155/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7994e-06 - val_loss: 1.8276e-06\n",
      "Epoch 156/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8944e-06 - val_loss: 1.8321e-06\n",
      "Epoch 157/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8232e-06 - val_loss: 1.8117e-06\n",
      "Epoch 158/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8602e-06 - val_loss: 1.8018e-06\n",
      "Epoch 159/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7779e-06 - val_loss: 1.7966e-06\n",
      "Epoch 160/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7450e-06 - val_loss: 1.7904e-06\n",
      "Epoch 161/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7225e-06 - val_loss: 1.7864e-06\n",
      "Epoch 162/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7440e-06 - val_loss: 1.7741e-06\n",
      "Epoch 163/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6885e-06 - val_loss: 1.7666e-06\n",
      "Epoch 164/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7124e-06 - val_loss: 1.7583e-06\n",
      "Epoch 165/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6354e-06 - val_loss: 1.7532e-06\n",
      "Epoch 166/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6059e-06 - val_loss: 1.7592e-06\n",
      "Epoch 167/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6828e-06 - val_loss: 1.7486e-06\n",
      "Epoch 168/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6821e-06 - val_loss: 1.7312e-06\n",
      "Epoch 169/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6737e-06 - val_loss: 1.7433e-06\n",
      "Epoch 170/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5786e-06 - val_loss: 1.7207e-06\n",
      "Epoch 171/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8566e-06 - val_loss: 1.7162e-06\n",
      "Epoch 172/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5888e-06 - val_loss: 1.7058e-06\n",
      "Epoch 173/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6792e-06 - val_loss: 1.6977e-06\n",
      "Epoch 174/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7344e-06 - val_loss: 1.6978e-06\n",
      "Epoch 175/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5869e-06 - val_loss: 1.6842e-06\n",
      "Epoch 176/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5735e-06 - val_loss: 1.6819e-06\n",
      "Epoch 177/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6741e-06 - val_loss: 1.6725e-06\n",
      "Epoch 178/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7405e-06 - val_loss: 1.6623e-06\n",
      "Epoch 179/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6875e-06 - val_loss: 1.6574e-06\n",
      "Epoch 180/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6553e-06 - val_loss: 1.6511e-06\n",
      "Epoch 181/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6439e-06 - val_loss: 1.6522e-06\n",
      "Epoch 182/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5586e-06 - val_loss: 1.6383e-06\n",
      "Epoch 183/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5626e-06 - val_loss: 1.6334e-06\n",
      "Epoch 184/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5815e-06 - val_loss: 1.6326e-06\n",
      "Epoch 185/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5543e-06 - val_loss: 1.6241e-06\n",
      "Epoch 186/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4932e-06 - val_loss: 1.6172e-06\n",
      "Epoch 187/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5564e-06 - val_loss: 1.6106e-06\n",
      "Epoch 188/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5974e-06 - val_loss: 1.6030e-06\n",
      "Epoch 189/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4718e-06 - val_loss: 1.6141e-06\n",
      "Epoch 190/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4966e-06 - val_loss: 1.5972e-06\n",
      "Epoch 191/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5387e-06 - val_loss: 1.5917e-06\n",
      "Epoch 192/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5872e-06 - val_loss: 1.5796e-06\n",
      "Epoch 193/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4699e-06 - val_loss: 1.5764e-06\n",
      "Epoch 194/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5005e-06 - val_loss: 1.5739e-06\n",
      "Epoch 195/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3632e-06 - val_loss: 1.5697e-06\n",
      "Epoch 196/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4286e-06 - val_loss: 1.5615e-06\n",
      "Epoch 197/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5301e-06 - val_loss: 1.5515e-06\n",
      "Epoch 198/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5882e-06 - val_loss: 1.5446e-06\n",
      "Epoch 199/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5020e-06 - val_loss: 1.5388e-06\n",
      "Epoch 200/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4802e-06 - val_loss: 1.5520e-06\n",
      "Epoch 201/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5203e-06 - val_loss: 1.5335e-06\n",
      "Epoch 202/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4882e-06 - val_loss: 1.5254e-06\n",
      "Epoch 203/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4942e-06 - val_loss: 1.5176e-06\n",
      "Epoch 204/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3871e-06 - val_loss: 1.5162e-06\n",
      "Epoch 205/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4499e-06 - val_loss: 1.5070e-06\n",
      "Epoch 206/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4148e-06 - val_loss: 1.5009e-06\n",
      "Epoch 207/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3737e-06 - val_loss: 1.4977e-06\n",
      "Epoch 208/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4126e-06 - val_loss: 1.4924e-06\n",
      "Epoch 209/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4197e-06 - val_loss: 1.4876e-06\n",
      "Epoch 210/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4346e-06 - val_loss: 1.4823e-06\n",
      "Epoch 211/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4302e-06 - val_loss: 1.4757e-06\n",
      "Epoch 212/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3386e-06 - val_loss: 1.4742e-06\n",
      "Epoch 213/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4300e-06 - val_loss: 1.4669e-06\n",
      "Epoch 214/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3381e-06 - val_loss: 1.4598e-06\n",
      "Epoch 215/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3694e-06 - val_loss: 1.4566e-06\n",
      "Epoch 216/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3538e-06 - val_loss: 1.4515e-06\n",
      "Epoch 217/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3649e-06 - val_loss: 1.4531e-06\n",
      "Epoch 218/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3854e-06 - val_loss: 1.4426e-06\n",
      "Epoch 219/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3918e-06 - val_loss: 1.4365e-06\n",
      "Epoch 220/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3411e-06 - val_loss: 1.4329e-06\n",
      "Epoch 221/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3072e-06 - val_loss: 1.4271e-06\n",
      "Epoch 222/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2916e-06 - val_loss: 1.4254e-06\n",
      "Epoch 223/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3217e-06 - val_loss: 1.4233e-06\n",
      "Epoch 224/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4473e-06 - val_loss: 1.4149e-06\n",
      "Epoch 225/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2758e-06 - val_loss: 1.4108e-06\n",
      "Epoch 226/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3782e-06 - val_loss: 1.4067e-06\n",
      "Epoch 227/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3659e-06 - val_loss: 1.3998e-06\n",
      "Epoch 228/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3144e-06 - val_loss: 1.3979e-06\n",
      "Epoch 229/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3547e-06 - val_loss: 1.3972e-06\n",
      "Epoch 230/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3160e-06 - val_loss: 1.3859e-06\n",
      "Epoch 231/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3891e-06 - val_loss: 1.3809e-06\n",
      "Epoch 232/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2752e-06 - val_loss: 1.3812e-06\n",
      "Epoch 233/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2486e-06 - val_loss: 1.3735e-06\n",
      "Epoch 234/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2215e-06 - val_loss: 1.3690e-06\n",
      "Epoch 235/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2171e-06 - val_loss: 1.3687e-06\n",
      "Epoch 236/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2509e-06 - val_loss: 1.3611e-06\n",
      "Epoch 237/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2469e-06 - val_loss: 1.3583e-06\n",
      "Epoch 238/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2042e-06 - val_loss: 1.3593e-06\n",
      "Epoch 239/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3495e-06 - val_loss: 1.3489e-06\n",
      "Epoch 240/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2856e-06 - val_loss: 1.3437e-06\n",
      "Epoch 241/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2566e-06 - val_loss: 1.3539e-06\n",
      "Epoch 242/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2339e-06 - val_loss: 1.3386e-06\n",
      "Epoch 243/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2457e-06 - val_loss: 1.3334e-06\n",
      "Epoch 244/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2836e-06 - val_loss: 1.3276e-06\n",
      "Epoch 245/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2100e-06 - val_loss: 1.3254e-06\n",
      "Epoch 246/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2708e-06 - val_loss: 1.3213e-06\n",
      "Epoch 247/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1912e-06 - val_loss: 1.3200e-06\n",
      "Epoch 248/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2171e-06 - val_loss: 1.3129e-06\n",
      "Epoch 249/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2070e-06 - val_loss: 1.3089e-06\n",
      "Epoch 250/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2135e-06 - val_loss: 1.3051e-06\n",
      "Epoch 251/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2995e-06 - val_loss: 1.3004e-06\n",
      "Epoch 252/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2032e-06 - val_loss: 1.3015e-06\n",
      "Epoch 253/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2025e-06 - val_loss: 1.2991e-06\n",
      "Epoch 254/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1176e-06 - val_loss: 1.2906e-06\n",
      "Epoch 255/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2232e-06 - val_loss: 1.2862e-06\n",
      "Epoch 256/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2712e-06 - val_loss: 1.2814e-06\n",
      "Epoch 257/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2163e-06 - val_loss: 1.2819e-06\n",
      "Epoch 258/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1996e-06 - val_loss: 1.2837e-06\n",
      "Epoch 259/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1771e-06 - val_loss: 1.2716e-06\n",
      "Epoch 260/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 1.1371e-06 - val_loss: 1.2677e-06\n",
      "Epoch 261/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1812e-06 - val_loss: 1.2647e-06\n",
      "Epoch 262/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1360e-06 - val_loss: 1.2627e-06\n",
      "Epoch 263/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1449e-06 - val_loss: 1.2645e-06\n",
      "Epoch 264/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1948e-06 - val_loss: 1.2553e-06\n",
      "Epoch 265/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1028e-06 - val_loss: 1.2534e-06\n",
      "Epoch 266/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2135e-06 - val_loss: 1.2495e-06\n",
      "Epoch 267/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0971e-06 - val_loss: 1.2451e-06\n",
      "Epoch 268/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1603e-06 - val_loss: 1.2396e-06\n",
      "Epoch 269/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1931e-06 - val_loss: 1.2374e-06\n",
      "Epoch 270/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1866e-06 - val_loss: 1.2359e-06\n",
      "Epoch 271/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0761e-06 - val_loss: 1.2354e-06\n",
      "Epoch 272/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0941e-06 - val_loss: 1.2264e-06\n",
      "Epoch 273/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1497e-06 - val_loss: 1.2250e-06\n",
      "Epoch 274/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0948e-06 - val_loss: 1.2255e-06\n",
      "Epoch 275/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0986e-06 - val_loss: 1.2178e-06\n",
      "Epoch 276/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0809e-06 - val_loss: 1.2143e-06\n",
      "Epoch 277/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1176e-06 - val_loss: 1.2095e-06\n",
      "Epoch 278/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1870e-06 - val_loss: 1.2091e-06\n",
      "Epoch 279/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1874e-06 - val_loss: 1.2052e-06\n",
      "Epoch 280/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0843e-06 - val_loss: 1.2060e-06\n",
      "Epoch 281/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0807e-06 - val_loss: 1.1973e-06\n",
      "Epoch 282/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1102e-06 - val_loss: 1.1948e-06\n",
      "Epoch 283/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1662e-06 - val_loss: 1.1926e-06\n",
      "Epoch 284/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1505e-06 - val_loss: 1.1886e-06\n",
      "Epoch 285/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1491e-06 - val_loss: 1.1878e-06\n",
      "Epoch 286/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1056e-06 - val_loss: 1.1820e-06\n",
      "Epoch 287/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1515e-06 - val_loss: 1.1790e-06\n",
      "Epoch 288/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0927e-06 - val_loss: 1.1743e-06\n",
      "Epoch 289/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1321e-06 - val_loss: 1.1718e-06\n",
      "Epoch 290/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0769e-06 - val_loss: 1.1693e-06\n",
      "Epoch 291/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1398e-06 - val_loss: 1.1677e-06\n",
      "Epoch 292/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0688e-06 - val_loss: 1.1653e-06\n",
      "Epoch 293/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0734e-06 - val_loss: 1.1602e-06\n",
      "Epoch 294/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.9584e-07 - val_loss: 1.1573e-06\n",
      "Epoch 295/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0107e-06 - val_loss: 1.1550e-06\n",
      "Epoch 296/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0244e-06 - val_loss: 1.1537e-06\n",
      "Epoch 297/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1016e-06 - val_loss: 1.1488e-06\n",
      "Epoch 298/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0695e-06 - val_loss: 1.1486e-06\n",
      "Epoch 299/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.8353e-07 - val_loss: 1.1486e-06\n",
      "Epoch 300/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0258e-06 - val_loss: 1.1407e-06\n",
      "Epoch 301/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0469e-06 - val_loss: 1.1370e-06\n",
      "Epoch 302/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0524e-06 - val_loss: 1.1324e-06\n",
      "Epoch 303/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0204e-06 - val_loss: 1.1304e-06\n",
      "Epoch 304/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0237e-06 - val_loss: 1.1306e-06\n",
      "Epoch 305/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0970e-06 - val_loss: 1.1248e-06\n",
      "Epoch 306/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0824e-06 - val_loss: 1.1226e-06\n",
      "Epoch 307/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0111e-06 - val_loss: 1.1203e-06\n",
      "Epoch 308/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0780e-06 - val_loss: 1.1139e-06\n",
      "Epoch 309/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0175e-06 - val_loss: 1.1124e-06\n",
      "Epoch 310/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.5457e-07 - val_loss: 1.1103e-06\n",
      "Epoch 311/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0262e-06 - val_loss: 1.1091e-06\n",
      "Epoch 312/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0242e-06 - val_loss: 1.1035e-06\n",
      "Epoch 313/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0502e-06 - val_loss: 1.1007e-06\n",
      "Epoch 314/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.7801e-07 - val_loss: 1.0992e-06\n",
      "Epoch 315/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0130e-06 - val_loss: 1.0953e-06\n",
      "Epoch 316/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0147e-06 - val_loss: 1.0967e-06\n",
      "Epoch 317/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0298e-06 - val_loss: 1.0897e-06\n",
      "Epoch 318/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0039e-06 - val_loss: 1.0870e-06\n",
      "Epoch 319/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.7362e-07 - val_loss: 1.0846e-06\n",
      "Epoch 320/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0634e-06 - val_loss: 1.0820e-06\n",
      "Epoch 321/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0149e-06 - val_loss: 1.0815e-06\n",
      "Epoch 322/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0492e-06 - val_loss: 1.0766e-06\n",
      "Epoch 323/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.3930e-07 - val_loss: 1.0727e-06\n",
      "Epoch 324/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.4594e-07 - val_loss: 1.0700e-06\n",
      "Epoch 325/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0346e-06 - val_loss: 1.0681e-06\n",
      "Epoch 326/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.5842e-07 - val_loss: 1.0651e-06\n",
      "Epoch 327/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.6206e-07 - val_loss: 1.0641e-06\n",
      "Epoch 328/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.1489e-07 - val_loss: 1.0606e-06\n",
      "Epoch 329/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.8499e-07 - val_loss: 1.0593e-06\n",
      "Epoch 330/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.7697e-07 - val_loss: 1.0579e-06\n",
      "Epoch 331/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.8244e-07 - val_loss: 1.0535e-06\n",
      "Epoch 332/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.3792e-07 - val_loss: 1.0501e-06\n",
      "Epoch 333/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.5968e-07 - val_loss: 1.0472e-06\n",
      "Epoch 334/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.5899e-07 - val_loss: 1.0467e-06\n",
      "Epoch 335/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.4543e-07 - val_loss: 1.0455e-06\n",
      "Epoch 336/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.2819e-07 - val_loss: 1.0401e-06\n",
      "Epoch 337/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.1040e-07 - val_loss: 1.0379e-06\n",
      "Epoch 338/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.6401e-07 - val_loss: 1.0343e-06\n",
      "Epoch 339/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.5414e-07 - val_loss: 1.0374e-06\n",
      "Epoch 340/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.1002e-07 - val_loss: 1.0302e-06\n",
      "Epoch 341/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.1290e-07 - val_loss: 1.0273e-06\n",
      "Epoch 342/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.2783e-07 - val_loss: 1.0243e-06\n",
      "Epoch 343/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.2260e-07 - val_loss: 1.0225e-06\n",
      "Epoch 344/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.7599e-07 - val_loss: 1.0206e-06\n",
      "Epoch 345/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.5062e-07 - val_loss: 1.0193e-06\n",
      "Epoch 346/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.6790e-07 - val_loss: 1.0168e-06\n",
      "Epoch 347/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0069e-06 - val_loss: 1.0135e-06\n",
      "Epoch 348/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.0824e-07 - val_loss: 1.0119e-06\n",
      "Epoch 349/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.6037e-07 - val_loss: 1.0166e-06\n",
      "Epoch 350/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.1100e-07 - val_loss: 1.0075e-06\n",
      "Epoch 351/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.0943e-07 - val_loss: 1.0044e-06\n",
      "Epoch 352/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.7639e-07 - val_loss: 1.0034e-06\n",
      "Epoch 353/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.7320e-07 - val_loss: 1.0001e-06\n",
      "Epoch 354/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.0491e-07 - val_loss: 9.9833e-07\n",
      "Epoch 355/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.6967e-07 - val_loss: 1.0001e-06\n",
      "Epoch 356/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.4012e-07 - val_loss: 9.9451e-07\n",
      "Epoch 357/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.0292e-07 - val_loss: 9.9180e-07\n",
      "Epoch 358/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.7645e-07 - val_loss: 9.9227e-07\n",
      "Epoch 359/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.5335e-07 - val_loss: 9.8801e-07\n",
      "Epoch 360/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.2176e-07 - val_loss: 9.8722e-07\n",
      "Epoch 361/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.0360e-07 - val_loss: 9.8329e-07\n",
      "Epoch 362/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.7082e-07 - val_loss: 9.8065e-07\n",
      "Epoch 363/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.9635e-07 - val_loss: 9.7948e-07\n",
      "Epoch 364/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.7904e-07 - val_loss: 9.7747e-07\n",
      "Epoch 365/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.4326e-07 - val_loss: 9.7535e-07\n",
      "Epoch 366/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.8886e-07 - val_loss: 9.7444e-07\n",
      "Epoch 367/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.7764e-07 - val_loss: 9.7080e-07\n",
      "Epoch 368/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.7116e-07 - val_loss: 9.7086e-07\n",
      "Epoch 369/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.9342e-07 - val_loss: 9.6752e-07\n",
      "Epoch 370/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.1535e-07 - val_loss: 9.6834e-07\n",
      "Epoch 371/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.8099e-07 - val_loss: 9.6449e-07\n",
      "Epoch 372/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.7805e-07 - val_loss: 9.6169e-07\n",
      "Epoch 373/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.8503e-07 - val_loss: 9.6002e-07\n",
      "Epoch 374/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.1674e-07 - val_loss: 9.5806e-07\n",
      "Epoch 375/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.7807e-07 - val_loss: 9.5625e-07\n",
      "Epoch 376/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.4694e-07 - val_loss: 9.5424e-07\n",
      "Epoch 377/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.4919e-07 - val_loss: 9.5217e-07\n",
      "Epoch 378/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.1622e-07 - val_loss: 9.5019e-07\n",
      "Epoch 379/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.5352e-07 - val_loss: 9.4841e-07\n",
      "Epoch 380/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.0579e-07 - val_loss: 9.4755e-07\n",
      "Epoch 381/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.1878e-07 - val_loss: 9.4508e-07\n",
      "Epoch 382/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.0382e-07 - val_loss: 9.4336e-07\n",
      "Epoch 383/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.6231e-07 - val_loss: 9.4251e-07\n",
      "Epoch 384/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.4542e-07 - val_loss: 9.3927e-07\n",
      "Epoch 385/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.3200e-07 - val_loss: 9.4148e-07\n",
      "Epoch 386/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.0735e-07 - val_loss: 9.4286e-07\n",
      "Epoch 387/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.0084e-07 - val_loss: 9.3317e-07\n",
      "Epoch 388/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.4459e-07 - val_loss: 9.3183e-07\n",
      "Epoch 389/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.8693e-07 - val_loss: 9.3470e-07\n",
      "Epoch 390/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.2209e-07 - val_loss: 9.2956e-07\n",
      "Epoch 391/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.1970e-07 - val_loss: 9.2799e-07\n",
      "Epoch 392/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.2631e-07 - val_loss: 9.2802e-07\n",
      "Epoch 393/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.3868e-07 - val_loss: 9.2542e-07\n",
      "Epoch 394/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.4751e-07 - val_loss: 9.2285e-07\n",
      "Epoch 395/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.4361e-07 - val_loss: 9.2063e-07\n",
      "Epoch 396/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5838e-07 - val_loss: 9.2150e-07\n",
      "Epoch 397/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.4922e-07 - val_loss: 9.1835e-07\n",
      "Epoch 398/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.7383e-07 - val_loss: 9.1526e-07\n",
      "Epoch 399/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.8705e-07 - val_loss: 9.1393e-07\n",
      "Epoch 400/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.0524e-07 - val_loss: 9.1215e-07\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=MY_OPTIMIZER)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=MY_EPOCHS, \n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "4df21ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curves\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 5e-4) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "eb432acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 8.8382e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0009106258037834069"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test_scaled, y_test)\n",
    "np.sqrt(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "181daa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test_scaled[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "ca87781a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748     6.582550e-08\n",
       "90      9.909022e-08\n",
       "3735    1.656921e-08\n",
       "Name: dv_st, dtype: float64"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "8d8a8fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00158797],\n",
       "       [-0.00161233],\n",
       "       [-0.00019164]], dtype=float32)"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d0bc8",
   "metadata": {},
   "source": [
    "# Fine-Tuning Neural Network Hyperparameters\n",
    "\n",
    "Wrap our Keras models in objects that mimic regular Scikit-Learn regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e052ee1",
   "metadata": {},
   "source": [
    "def build_model(n_hidden, n_neurons, learning_rate, \n",
    "                input_shape):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", \n",
    "                                     **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, **options))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "keras_reg = KerasRegressor(build_model, n_hidden=1, n_neurons=30, learning_rate=3e-3, \n",
    "                input_shape=[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "8a171888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    #model.add(layers.Flatten())\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 5)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "               # Tune number of units separately for each layer.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                activation=\"relu\",\n",
    "            )\n",
    "        )\n",
    "    model.add(layers.Dense(1))\n",
    "    #learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        #optimizer=keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "        optimizer=MY_OPTIMIZER,\n",
    "        loss=\"mean_squared_error\",\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "537260cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential_2, built=False>"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quickly test if model builds successfuly\n",
    "import keras_tuner\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894b3759",
   "metadata": {},
   "source": [
    "Use a randomized search to train hundreds of hyperparameter combinations  and see which one performs best on the validation set.\n",
    "\n",
    "Note that RandomizedSearchCV uses K-fold cross-validation, so it\n",
    "does not use X_valid and y_valid . These are just used for early stopping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf98fb",
   "metadata": {},
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, \n",
    "                                   n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "46016dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "04174a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# print a summary of the search space\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dac7ce",
   "metadata": {},
   "source": [
    "Then, start the search for the best hyperparameter configuration. All the arguments passed to search is passed to model.fit() in each execution. Remember to pass validation_data to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "2b9dc4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 01m 48s]\n",
      "val_loss: 1.0641588374937783e-06\n",
      "\n",
      "Best val_loss So Far: 1.0641588374937783e-06\n",
      "Total elapsed time: 00h 03m 15s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "5                 |3                 |num_layers\n",
      "96                |128               |units_0\n",
      "224               |480               |units_1\n",
      "448               |32                |units_2\n",
      "\n",
      "Epoch 1/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.7553e-05 - val_loss: 2.6102e-05\n",
      "Epoch 2/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1296e-05 - val_loss: 1.8634e-05\n",
      "Epoch 3/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5503e-05 - val_loss: 1.5077e-05\n",
      "Epoch 4/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2692e-05 - val_loss: 1.3012e-05\n",
      "Epoch 5/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0669e-05 - val_loss: 1.1490e-05\n",
      "Epoch 6/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3959e-06 - val_loss: 1.0211e-05\n",
      "Epoch 7/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4659e-06 - val_loss: 9.1961e-06\n",
      "Epoch 8/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8241e-06 - val_loss: 8.3642e-06\n",
      "Epoch 9/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4852e-06 - val_loss: 7.6644e-06\n",
      "Epoch 10/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3496e-06 - val_loss: 7.0295e-06\n",
      "Epoch 11/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3218e-06 - val_loss: 6.5439e-06\n",
      "Epoch 12/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0025e-06 - val_loss: 6.1609e-06\n",
      "Epoch 13/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4450e-06 - val_loss: 5.8384e-06\n",
      "Epoch 14/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0444e-06 - val_loss: 5.5283e-06\n",
      "Epoch 15/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0221e-06 - val_loss: 5.2903e-06\n",
      "Epoch 16/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6548e-06 - val_loss: 5.0469e-06\n",
      "Epoch 17/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6513e-06 - val_loss: 4.8584e-06\n",
      "Epoch 18/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4163e-06 - val_loss: 4.6711e-06\n",
      "Epoch 19/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0627e-06 - val_loss: 4.5078e-06\n",
      "Epoch 20/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2001e-06 - val_loss: 4.3467e-06\n",
      "Epoch 21/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9541e-06 - val_loss: 4.1917e-06\n",
      "Epoch 22/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7791e-06 - val_loss: 4.0633e-06\n",
      "Epoch 23/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5617e-06 - val_loss: 3.9230e-06\n",
      "Epoch 24/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4497e-06 - val_loss: 3.7901e-06\n",
      "Epoch 25/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3322e-06 - val_loss: 3.6748e-06\n",
      "Epoch 26/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2844e-06 - val_loss: 3.5677e-06\n",
      "Epoch 27/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1195e-06 - val_loss: 3.4559e-06\n",
      "Epoch 28/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1052e-06 - val_loss: 3.3574e-06\n",
      "Epoch 29/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1803e-06 - val_loss: 3.2651e-06\n",
      "Epoch 30/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9739e-06 - val_loss: 3.1670e-06\n",
      "Epoch 31/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7725e-06 - val_loss: 3.0794e-06\n",
      "Epoch 32/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8902e-06 - val_loss: 2.9909e-06\n",
      "Epoch 33/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5821e-06 - val_loss: 2.9191e-06\n",
      "Epoch 34/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6154e-06 - val_loss: 2.8378e-06\n",
      "Epoch 35/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5078e-06 - val_loss: 2.7554e-06\n",
      "Epoch 36/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3927e-06 - val_loss: 2.6976e-06\n",
      "Epoch 37/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3042e-06 - val_loss: 2.6240e-06\n",
      "Epoch 38/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3343e-06 - val_loss: 2.5501e-06\n",
      "Epoch 39/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2937e-06 - val_loss: 2.4887e-06\n",
      "Epoch 40/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1710e-06 - val_loss: 2.4297e-06\n",
      "Epoch 41/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0988e-06 - val_loss: 2.3684e-06\n",
      "Epoch 42/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0890e-06 - val_loss: 2.3106e-06\n",
      "Epoch 43/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0320e-06 - val_loss: 2.2654e-06\n",
      "Epoch 44/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1417e-06 - val_loss: 2.2052e-06\n",
      "Epoch 45/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0038e-06 - val_loss: 2.1579e-06\n",
      "Epoch 46/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9462e-06 - val_loss: 2.1069e-06\n",
      "Epoch 47/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8480e-06 - val_loss: 2.0671e-06\n",
      "Epoch 48/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8176e-06 - val_loss: 2.0219e-06\n",
      "Epoch 49/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8392e-06 - val_loss: 1.9760e-06\n",
      "Epoch 50/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7407e-06 - val_loss: 1.9297e-06\n",
      "Epoch 51/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7142e-06 - val_loss: 1.8901e-06\n",
      "Epoch 52/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7480e-06 - val_loss: 1.8512e-06\n",
      "Epoch 53/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5601e-06 - val_loss: 1.8113e-06\n",
      "Epoch 54/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4879e-06 - val_loss: 1.7720e-06\n",
      "Epoch 55/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5442e-06 - val_loss: 1.7366e-06\n",
      "Epoch 56/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5567e-06 - val_loss: 1.7028e-06\n",
      "Epoch 57/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5084e-06 - val_loss: 1.6661e-06\n",
      "Epoch 58/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4166e-06 - val_loss: 1.6359e-06\n",
      "Epoch 59/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4349e-06 - val_loss: 1.6070e-06\n",
      "Epoch 60/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3752e-06 - val_loss: 1.5721e-06\n",
      "Epoch 61/400\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3547e-06 - val_loss: 1.5413e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/400\n",
      "\u001b[1m41/81\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4154e-06 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[495], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch(X_train_scaled, y_train, epochs\u001b[38;5;241m=\u001b[39mMY_EPOCHS, validation_data\u001b[38;5;241m=\u001b[39m(X_valid_scaled, y_valid))\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:323\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 323\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    325\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(X_train_scaled, y_train, epochs=MY_EPOCHS, validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d5b759",
   "metadata": {},
   "source": [
    "## Query the results\n",
    "When search is over, you can retrieve the best model(s). The model is saved at its best performing epoch evaluated on the validation_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d995384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse_test = best_model.evaluate(X_test_scaled, y_test)\n",
    "np.sqrt(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9226c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test_scaled[:3] # pretend these are new instances\n",
    "y_pred = best_model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b7814",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc967704",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04410338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:halo]",
   "language": "python",
   "name": "conda-env-halo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
