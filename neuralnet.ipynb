{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2ec2f4",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8392002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a3f2b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n",
      "3.0.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc26703",
   "metadata": {},
   "source": [
    "## Define global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ee56892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MY_OPTIMIZER = \"SGD\"\n",
    "# MY_EPOCHS = 1000\n",
    "# MY_LEARNING_RATE = 0.000001\n",
    "# MY_BATCH_SIZE = 2048\n",
    "MY_EPOCHS = 1000\n",
    "MY_LEARNING_RATE = 0.000001\n",
    "MY_BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf698e1",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e284cb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2051, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maneuvers = pd.read_csv(\"maneuvers.csv\")\n",
    "#maneuvers.head()\n",
    "maneuvers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8d29c78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>dz</th>\n",
       "      <th>dv_st</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2.051000e+03</td>\n",
       "      <td>2.051000e+03</td>\n",
       "      <td>2.051000e+03</td>\n",
       "      <td>2.051000e+03</td>\n",
       "      <td>2.051000e+03</td>\n",
       "      <td>2.051000e+03</td>\n",
       "      <td>2.051000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3144.884951</td>\n",
       "      <td>-9.916647e-01</td>\n",
       "      <td>1.357625e-07</td>\n",
       "      <td>8.983636e-04</td>\n",
       "      <td>2.772001e-08</td>\n",
       "      <td>9.931020e-03</td>\n",
       "      <td>-7.613491e-08</td>\n",
       "      <td>1.678592e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1811.726067</td>\n",
       "      <td>1.058217e-09</td>\n",
       "      <td>1.202943e-07</td>\n",
       "      <td>5.307901e-09</td>\n",
       "      <td>2.456665e-08</td>\n",
       "      <td>3.606267e-09</td>\n",
       "      <td>6.736846e-08</td>\n",
       "      <td>8.925691e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.177680</td>\n",
       "      <td>-9.916647e-01</td>\n",
       "      <td>-8.264015e-11</td>\n",
       "      <td>8.983543e-04</td>\n",
       "      <td>-1.957939e-11</td>\n",
       "      <td>9.931014e-03</td>\n",
       "      <td>-2.261367e-07</td>\n",
       "      <td>1.380825e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1577.031315</td>\n",
       "      <td>-9.916647e-01</td>\n",
       "      <td>2.668074e-08</td>\n",
       "      <td>8.983590e-04</td>\n",
       "      <td>5.438768e-09</td>\n",
       "      <td>9.931017e-03</td>\n",
       "      <td>-1.280591e-07</td>\n",
       "      <td>1.618974e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3144.884951</td>\n",
       "      <td>-9.916647e-01</td>\n",
       "      <td>1.027174e-07</td>\n",
       "      <td>8.983636e-04</td>\n",
       "      <td>2.097238e-08</td>\n",
       "      <td>9.931020e-03</td>\n",
       "      <td>-5.764007e-08</td>\n",
       "      <td>1.676073e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4712.738586</td>\n",
       "      <td>-9.916647e-01</td>\n",
       "      <td>2.282766e-07</td>\n",
       "      <td>8.983682e-04</td>\n",
       "      <td>4.661922e-08</td>\n",
       "      <td>9.931023e-03</td>\n",
       "      <td>-1.495125e-08</td>\n",
       "      <td>1.737429e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6280.592222</td>\n",
       "      <td>-9.916647e-01</td>\n",
       "      <td>4.033941e-07</td>\n",
       "      <td>8.983727e-04</td>\n",
       "      <td>8.238304e-08</td>\n",
       "      <td>9.931027e-03</td>\n",
       "      <td>-5.776291e-12</td>\n",
       "      <td>2.054861e-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 t             x             y             z            dx  \\\n",
       "count  2051.000000  2.051000e+03  2.051000e+03  2.051000e+03  2.051000e+03   \n",
       "mean   3144.884951 -9.916647e-01  1.357625e-07  8.983636e-04  2.772001e-08   \n",
       "std    1811.726067  1.058217e-09  1.202943e-07  5.307901e-09  2.456665e-08   \n",
       "min       9.177680 -9.916647e-01 -8.264015e-11  8.983543e-04 -1.957939e-11   \n",
       "25%    1577.031315 -9.916647e-01  2.668074e-08  8.983590e-04  5.438768e-09   \n",
       "50%    3144.884951 -9.916647e-01  1.027174e-07  8.983636e-04  2.097238e-08   \n",
       "75%    4712.738586 -9.916647e-01  2.282766e-07  8.983682e-04  4.661922e-08   \n",
       "max    6280.592222 -9.916647e-01  4.033941e-07  8.983727e-04  8.238304e-08   \n",
       "\n",
       "                 dy            dz         dv_st  \n",
       "count  2.051000e+03  2.051000e+03  2.051000e+03  \n",
       "mean   9.931020e-03 -7.613491e-08  1.678592e-11  \n",
       "std    3.606267e-09  6.736846e-08  8.925691e-13  \n",
       "min    9.931014e-03 -2.261367e-07  1.380825e-11  \n",
       "25%    9.931017e-03 -1.280591e-07  1.618974e-11  \n",
       "50%    9.931020e-03 -5.764007e-08  1.676073e-11  \n",
       "75%    9.931023e-03 -1.495125e-08  1.737429e-11  \n",
       "max    9.931027e-03 -5.776291e-12  2.054861e-11  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maneuvers.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b34847",
   "metadata": {},
   "source": [
    "## Add/Drop Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157af24d",
   "metadata": {},
   "source": [
    "Try adding new attribute \"angle\" = angle in the periodic orbit, which is essentially time/period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e0d4535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop dx and dz features, since they are almost proportional to y\n",
    "#maneuvers = maneuvers.drop([\"dx\", \"dz\"], axis=1)\n",
    "\n",
    "#maneuvers[\"angle\"]=maneuvers[\"t\"].apply(lambda x: math.fmod(x, 0.3059226605957322E+01))\n",
    "maneuvers = maneuvers.drop([\"t\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bee80c",
   "metadata": {},
   "source": [
    "# Prepare the Data for Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cbc65d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's separate the predictors and the labels\n",
    "maneuvers_predictors = maneuvers.drop(\"dv_st\", axis=1)\n",
    "maneuvers_labels = maneuvers[[\"dv_st\"]].copy()\n",
    "\n",
    "# Convert dataframe to a numpy array before training, to avoid issues with dataframe headers.\n",
    "maneuvers_predictors = maneuvers_predictors.to_numpy()\n",
    "maneuvers_labels = maneuvers_labels.to_numpy()\n",
    "\n",
    "#maneuvers_predictors.head()\n",
    "#maneuvers_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0619848",
   "metadata": {},
   "source": [
    "## Create a Train/Test/Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "403ea1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1230, 6)\n",
      "(411, 6)\n",
      "(410, 6)\n",
      "[[-9.91664719e-01  1.47469339e-07  8.98365318e-04  3.01132075e-08\n",
      "   9.93102161e-03 -8.27352873e-08]\n",
      " [-9.91664720e-01  3.72324137e-07  8.98372000e-04  7.60242345e-08\n",
      "   9.93102602e-03 -2.08492990e-07]\n",
      " [-9.91664718e-01  5.21773785e-08  8.98360912e-04  1.06556627e-08\n",
      "   9.93101844e-03 -2.94254043e-08]\n",
      " [-9.91664719e-01  2.45778240e-07  8.98368727e-04  5.01926119e-08\n",
      "   9.93102374e-03 -1.37855880e-07]]\n"
     ]
    }
   ],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "maneuvers_predictors, maneuvers_labels, test_size=0.2, random_state=1)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_train[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad507e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39821666, 0.36570134, 0.59785989, 0.36567755, 0.60553031,\n",
       "        0.6341521 ],\n",
       "       [0.04031593, 0.92299443, 0.96204313, 0.92283251, 0.95834889,\n",
       "        0.07802418],\n",
       "       [0.64672697, 0.12952424, 0.3577235 , 0.12954979, 0.35151403,\n",
       "        0.8699    ],\n",
       "       [0.22192281, 0.60935579, 0.78365068, 0.6093519 , 0.77571014,\n",
       "        0.39039685],\n",
       "       [0.44693154, 0.31165182, 0.5602173 , 0.31163707, 0.54990357,\n",
       "        0.68805182]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale all the features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a061776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39826457],\n",
       "       [0.54160334],\n",
       "       [0.34155912],\n",
       "       [0.5423771 ],\n",
       "       [0.56390416]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale target variable dv_st as well.\n",
    "# Rationale: dv_st takes very small values (10^{-8}), \n",
    "# so MSE may be tiny and not computed properly. Also, NN may converge faster?\n",
    "\n",
    "scaler_target = MinMaxScaler()\n",
    "y_train_scaled = scaler_target.fit_transform(y_train)\n",
    "y_valid_scaled = scaler_target.transform(y_valid)\n",
    "y_test_scaled = scaler_target.transform(y_test)\n",
    "y_train_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd21f418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39821666, 0.36570134, 0.59785989, 0.36567755, 0.60553031,\n",
       "        0.6341521 , 0.15857651, 0.14562837, 0.23807777, 0.14561889,\n",
       "        0.24113226, 0.25252994, 0.13373747, 0.21863816, 0.13372877,\n",
       "        0.22144324, 0.23191027, 0.35743644, 0.21862394, 0.36202228,\n",
       "        0.37913411, 0.13372007, 0.22142884, 0.23189519, 0.36666695,\n",
       "        0.38399832, 0.40214889],\n",
       "       [0.04031593, 0.92299443, 0.96204313, 0.92283251, 0.95834889,\n",
       "        0.07802418, 0.00162537, 0.03721138, 0.03878566, 0.03720485,\n",
       "        0.03863672, 0.00314562, 0.85191873, 0.88796046, 0.85176927,\n",
       "        0.88455069, 0.07201589, 0.92552699, 0.88780468, 0.92197297,\n",
       "        0.07506263, 0.85161984, 0.88439551, 0.07200325, 0.91843259,\n",
       "        0.07477439, 0.00608777],\n",
       "       [0.64672697, 0.12952424, 0.3577235 , 0.12954979, 0.35151403,\n",
       "        0.8699    , 0.41825577, 0.08376682, 0.23134944, 0.08378335,\n",
       "        0.2273336 , 0.56258779, 0.01677653, 0.04633387, 0.01677984,\n",
       "        0.04552959, 0.11267314, 0.12796611, 0.04634301, 0.12574483,\n",
       "        0.31118368, 0.01678315, 0.04553857, 0.11269537, 0.12356212,\n",
       "        0.30578206, 0.75672602],\n",
       "       [0.22192281, 0.60935579, 0.78365068, 0.6093519 , 0.77571014,\n",
       "        0.39039685, 0.04924974, 0.13522995, 0.17390997, 0.13522909,\n",
       "        0.17214778, 0.08663797, 0.37131447, 0.47752208, 0.37131211,\n",
       "        0.47268346, 0.23789058, 0.61410839, 0.47751903, 0.60788578,\n",
       "        0.30593476, 0.37130974, 0.47268045, 0.23788906, 0.60172622,\n",
       "        0.30283479, 0.1524097 ],\n",
       "       [0.44693154, 0.31165182, 0.5602173 , 0.31163707, 0.54990357,\n",
       "        0.68805182, 0.1997478 , 0.13928703, 0.25037878, 0.13928044,\n",
       "        0.24576925, 0.30751206, 0.09712685, 0.17459274, 0.09712226,\n",
       "        0.17137845, 0.2144326 , 0.31384342, 0.17458448, 0.30806549,\n",
       "        0.38545853, 0.09711766, 0.17137034, 0.21442245, 0.30239393,\n",
       "        0.37836215, 0.47341531]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try adding degree 2 polynomial features. This worked well for polynomial regression \n",
    "# (see supervised.py).\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_scaled = poly_features.fit_transform(X_train_scaled)\n",
    "X_valid_scaled = poly_features.transform(X_valid_scaled)\n",
    "X_test_scaled = poly_features.transform(X_test_scaled)\n",
    "\n",
    "X_train_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27719c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_target.gz']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, 'scaler.gz')\n",
    "joblib.dump(scaler_target, 'scaler_target.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c083450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition number is 5.575073037645295e+17, max eigenvalue 1.52+0.00j\n"
     ]
    }
   ],
   "source": [
    "cov=np.cov(X_train_scaled, rowvar=False)\n",
    "cond = np.linalg.cond(cov)\n",
    "max_eig = np.linalg.eigvals(cov).max()\n",
    "print(f\"condition number is {cond}, max eigenvalue {max_eig:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac054552",
   "metadata": {},
   "source": [
    "# Building, Training, and Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ce2bc",
   "metadata": {},
   "source": [
    "The output layer has a single neuron (since we only want to\n",
    "predict a single value) and uses no activation function, and the loss function is the mean squared error. \n",
    "\n",
    "Since the dataset is quite noisy, we just use a single hidden layer with fewer neurons than before, to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee78d856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/anaconda3/envs/halo/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │         \u001b[38;5;34m8,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,601</span> (150.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,601\u001b[0m (150.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,601</span> (150.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,601\u001b[0m (150.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Dense(300, activation=\"relu\", input_shape=X_train_scaled.shape[1:]),\n",
    "keras.layers.Dense(100, activation=\"relu\"),\n",
    "keras.layers.Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c139b9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2313 - val_loss: 0.2252\n",
      "Epoch 2/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2292 - val_loss: 0.2236\n",
      "Epoch 3/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2279 - val_loss: 0.2220\n",
      "Epoch 4/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2265 - val_loss: 0.2204\n",
      "Epoch 5/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2271 - val_loss: 0.2187\n",
      "Epoch 6/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2202 - val_loss: 0.2172\n",
      "Epoch 7/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2224 - val_loss: 0.2156\n",
      "Epoch 8/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2139 - val_loss: 0.2140\n",
      "Epoch 9/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2202 - val_loss: 0.2125\n",
      "Epoch 10/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2146 - val_loss: 0.2109\n",
      "Epoch 11/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2154 - val_loss: 0.2094\n",
      "Epoch 12/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2113 - val_loss: 0.2079\n",
      "Epoch 13/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2149 - val_loss: 0.2063\n",
      "Epoch 14/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2140 - val_loss: 0.2048\n",
      "Epoch 15/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2120 - val_loss: 0.2034\n",
      "Epoch 16/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2088 - val_loss: 0.2019\n",
      "Epoch 17/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2072 - val_loss: 0.2004\n",
      "Epoch 18/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2036 - val_loss: 0.1989\n",
      "Epoch 19/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1997 - val_loss: 0.1975\n",
      "Epoch 20/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2017 - val_loss: 0.1960\n",
      "Epoch 21/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2025 - val_loss: 0.1946\n",
      "Epoch 22/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1945 - val_loss: 0.1932\n",
      "Epoch 23/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1971 - val_loss: 0.1918\n",
      "Epoch 24/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1923 - val_loss: 0.1904\n",
      "Epoch 25/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1940 - val_loss: 0.1890\n",
      "Epoch 26/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1897 - val_loss: 0.1876\n",
      "Epoch 27/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1908 - val_loss: 0.1862\n",
      "Epoch 28/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1877 - val_loss: 0.1848\n",
      "Epoch 29/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1857 - val_loss: 0.1835\n",
      "Epoch 30/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1862 - val_loss: 0.1821\n",
      "Epoch 31/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1846 - val_loss: 0.1808\n",
      "Epoch 32/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1847 - val_loss: 0.1795\n",
      "Epoch 33/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1838 - val_loss: 0.1781\n",
      "Epoch 34/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1856 - val_loss: 0.1768\n",
      "Epoch 35/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1813 - val_loss: 0.1755\n",
      "Epoch 36/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1799 - val_loss: 0.1742\n",
      "Epoch 37/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1769 - val_loss: 0.1730\n",
      "Epoch 38/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1766 - val_loss: 0.1717\n",
      "Epoch 39/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1799 - val_loss: 0.1704\n",
      "Epoch 40/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1707 - val_loss: 0.1692\n",
      "Epoch 41/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1724 - val_loss: 0.1679\n",
      "Epoch 42/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1698 - val_loss: 0.1667\n",
      "Epoch 43/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1689 - val_loss: 0.1655\n",
      "Epoch 44/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1691 - val_loss: 0.1643\n",
      "Epoch 45/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1723 - val_loss: 0.1631\n",
      "Epoch 46/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1686 - val_loss: 0.1619\n",
      "Epoch 47/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1601 - val_loss: 0.1607\n",
      "Epoch 48/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1645 - val_loss: 0.1595\n",
      "Epoch 49/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1654 - val_loss: 0.1583\n",
      "Epoch 50/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1591 - val_loss: 0.1572\n",
      "Epoch 51/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1609 - val_loss: 0.1560\n",
      "Epoch 52/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1615 - val_loss: 0.1549\n",
      "Epoch 53/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1597 - val_loss: 0.1537\n",
      "Epoch 54/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1552 - val_loss: 0.1526\n",
      "Epoch 55/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1614 - val_loss: 0.1515\n",
      "Epoch 56/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1592 - val_loss: 0.1504\n",
      "Epoch 57/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1541 - val_loss: 0.1493\n",
      "Epoch 58/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1494 - val_loss: 0.1482\n",
      "Epoch 59/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1499 - val_loss: 0.1471\n",
      "Epoch 60/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1479 - val_loss: 0.1460\n",
      "Epoch 61/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1480 - val_loss: 0.1449\n",
      "Epoch 62/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1499 - val_loss: 0.1439\n",
      "Epoch 63/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1500 - val_loss: 0.1428\n",
      "Epoch 64/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1417 - val_loss: 0.1417\n",
      "Epoch 65/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1427 - val_loss: 0.1407\n",
      "Epoch 66/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1448 - val_loss: 0.1397\n",
      "Epoch 67/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1443 - val_loss: 0.1386\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1375 - val_loss: 0.1376\n",
      "Epoch 69/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1423 - val_loss: 0.1366\n",
      "Epoch 70/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1407 - val_loss: 0.1356\n",
      "Epoch 71/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1374 - val_loss: 0.1346\n",
      "Epoch 72/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1418 - val_loss: 0.1336\n",
      "Epoch 73/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1378 - val_loss: 0.1326\n",
      "Epoch 74/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1357 - val_loss: 0.1316\n",
      "Epoch 75/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1337 - val_loss: 0.1307\n",
      "Epoch 76/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1357 - val_loss: 0.1297\n",
      "Epoch 77/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1282 - val_loss: 0.1287\n",
      "Epoch 78/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1314 - val_loss: 0.1278\n",
      "Epoch 79/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1325 - val_loss: 0.1268\n",
      "Epoch 80/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1305 - val_loss: 0.1259\n",
      "Epoch 81/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1325 - val_loss: 0.1249\n",
      "Epoch 82/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1279 - val_loss: 0.1240\n",
      "Epoch 83/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1282 - val_loss: 0.1231\n",
      "Epoch 84/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1280 - val_loss: 0.1222\n",
      "Epoch 85/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1278 - val_loss: 0.1213\n",
      "Epoch 86/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1227 - val_loss: 0.1203\n",
      "Epoch 87/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1248 - val_loss: 0.1194\n",
      "Epoch 88/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1224 - val_loss: 0.1186\n",
      "Epoch 89/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1225 - val_loss: 0.1177\n",
      "Epoch 90/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1238 - val_loss: 0.1168\n",
      "Epoch 91/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1165 - val_loss: 0.1159\n",
      "Epoch 92/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1236 - val_loss: 0.1150\n",
      "Epoch 93/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1192 - val_loss: 0.1142\n",
      "Epoch 94/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1175 - val_loss: 0.1133\n",
      "Epoch 95/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1170 - val_loss: 0.1125\n",
      "Epoch 96/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1175 - val_loss: 0.1117\n",
      "Epoch 97/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1144 - val_loss: 0.1108\n",
      "Epoch 98/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1135 - val_loss: 0.1100\n",
      "Epoch 99/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1126 - val_loss: 0.1092\n",
      "Epoch 100/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1096 - val_loss: 0.1084\n",
      "Epoch 101/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1116 - val_loss: 0.1076\n",
      "Epoch 102/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1075 - val_loss: 0.1068\n",
      "Epoch 103/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1097 - val_loss: 0.1060\n",
      "Epoch 104/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1090 - val_loss: 0.1052\n",
      "Epoch 105/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1060 - val_loss: 0.1044\n",
      "Epoch 106/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1064 - val_loss: 0.1036\n",
      "Epoch 107/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1045 - val_loss: 0.1029\n",
      "Epoch 108/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1053 - val_loss: 0.1021\n",
      "Epoch 109/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1010 - val_loss: 0.1013\n",
      "Epoch 110/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1056 - val_loss: 0.1006\n",
      "Epoch 111/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1049 - val_loss: 0.0998\n",
      "Epoch 112/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1057 - val_loss: 0.0991\n",
      "Epoch 113/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1026 - val_loss: 0.0984\n",
      "Epoch 114/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0997 - val_loss: 0.0977\n",
      "Epoch 115/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1032 - val_loss: 0.0969\n",
      "Epoch 116/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0999 - val_loss: 0.0962\n",
      "Epoch 117/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0992 - val_loss: 0.0955\n",
      "Epoch 118/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0957 - val_loss: 0.0948\n",
      "Epoch 119/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0971 - val_loss: 0.0941\n",
      "Epoch 120/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0972 - val_loss: 0.0934\n",
      "Epoch 121/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0975 - val_loss: 0.0927\n",
      "Epoch 122/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0963 - val_loss: 0.0920\n",
      "Epoch 123/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0962 - val_loss: 0.0914\n",
      "Epoch 124/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0917 - val_loss: 0.0907\n",
      "Epoch 125/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0956 - val_loss: 0.0900\n",
      "Epoch 126/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0911 - val_loss: 0.0894\n",
      "Epoch 127/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0905 - val_loss: 0.0887\n",
      "Epoch 128/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0913 - val_loss: 0.0881\n",
      "Epoch 129/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0907 - val_loss: 0.0874\n",
      "Epoch 130/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0919 - val_loss: 0.0868\n",
      "Epoch 131/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0854 - val_loss: 0.0861\n",
      "Epoch 132/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0904 - val_loss: 0.0855\n",
      "Epoch 133/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0890 - val_loss: 0.0849\n",
      "Epoch 134/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0864 - val_loss: 0.0843\n",
      "Epoch 135/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0875 - val_loss: 0.0836\n",
      "Epoch 136/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0840 - val_loss: 0.0830\n",
      "Epoch 137/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0845 - val_loss: 0.0824\n",
      "Epoch 138/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0835 - val_loss: 0.0818\n",
      "Epoch 139/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0845 - val_loss: 0.0812\n",
      "Epoch 140/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0828 - val_loss: 0.0806\n",
      "Epoch 141/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0811 - val_loss: 0.0800\n",
      "Epoch 142/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0808 - val_loss: 0.0795\n",
      "Epoch 143/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0830 - val_loss: 0.0789\n",
      "Epoch 144/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0777 - val_loss: 0.0783\n",
      "Epoch 145/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0799 - val_loss: 0.0777\n",
      "Epoch 146/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0804 - val_loss: 0.0772\n",
      "Epoch 147/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0782 - val_loss: 0.0766\n",
      "Epoch 148/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0801 - val_loss: 0.0761\n",
      "Epoch 149/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0795 - val_loss: 0.0755\n",
      "Epoch 150/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0781 - val_loss: 0.0750\n",
      "Epoch 151/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0744 - val_loss: 0.0744\n",
      "Epoch 152/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0743 - val_loss: 0.0739\n",
      "Epoch 153/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0755 - val_loss: 0.0734\n",
      "Epoch 154/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0758 - val_loss: 0.0728\n",
      "Epoch 155/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0712 - val_loss: 0.0723\n",
      "Epoch 156/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0728 - val_loss: 0.0718\n",
      "Epoch 157/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0722 - val_loss: 0.0713\n",
      "Epoch 158/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0763 - val_loss: 0.0708\n",
      "Epoch 159/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0757 - val_loss: 0.0703\n",
      "Epoch 160/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0717 - val_loss: 0.0698\n",
      "Epoch 161/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0706 - val_loss: 0.0693\n",
      "Epoch 162/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0728 - val_loss: 0.0688\n",
      "Epoch 163/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0726 - val_loss: 0.0683\n",
      "Epoch 164/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0719 - val_loss: 0.0678\n",
      "Epoch 165/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0702 - val_loss: 0.0674\n",
      "Epoch 166/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0682 - val_loss: 0.0669\n",
      "Epoch 167/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0674 - val_loss: 0.0664\n",
      "Epoch 168/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0686 - val_loss: 0.0659\n",
      "Epoch 169/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0699 - val_loss: 0.0654\n",
      "Epoch 170/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0668 - val_loss: 0.0650\n",
      "Epoch 171/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0666 - val_loss: 0.0645\n",
      "Epoch 172/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0675 - val_loss: 0.0640\n",
      "Epoch 173/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0676 - val_loss: 0.0636\n",
      "Epoch 174/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0644 - val_loss: 0.0631\n",
      "Epoch 175/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0668 - val_loss: 0.0626\n",
      "Epoch 176/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0646 - val_loss: 0.0622\n",
      "Epoch 177/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0652 - val_loss: 0.0618\n",
      "Epoch 178/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0643 - val_loss: 0.0613\n",
      "Epoch 179/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0633 - val_loss: 0.0609\n",
      "Epoch 180/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0631 - val_loss: 0.0604\n",
      "Epoch 181/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0615 - val_loss: 0.0600\n",
      "Epoch 182/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0627 - val_loss: 0.0596\n",
      "Epoch 183/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0626 - val_loss: 0.0592\n",
      "Epoch 184/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0615 - val_loss: 0.0587\n",
      "Epoch 185/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0611 - val_loss: 0.0583\n",
      "Epoch 186/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0621 - val_loss: 0.0579\n",
      "Epoch 187/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0595 - val_loss: 0.0575\n",
      "Epoch 188/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0610 - val_loss: 0.0571\n",
      "Epoch 189/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0572 - val_loss: 0.0567\n",
      "Epoch 190/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0591 - val_loss: 0.0563\n",
      "Epoch 191/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0562 - val_loss: 0.0559\n",
      "Epoch 192/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0555\n",
      "Epoch 193/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0561 - val_loss: 0.0552\n",
      "Epoch 194/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0571 - val_loss: 0.0548\n",
      "Epoch 195/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0569 - val_loss: 0.0544\n",
      "Epoch 196/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0569 - val_loss: 0.0540\n",
      "Epoch 197/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0564 - val_loss: 0.0537\n",
      "Epoch 198/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0557 - val_loss: 0.0533\n",
      "Epoch 199/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0544 - val_loss: 0.0529\n",
      "Epoch 200/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0569 - val_loss: 0.0526\n",
      "Epoch 201/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0554 - val_loss: 0.0522\n",
      "Epoch 202/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0528 - val_loss: 0.0519\n",
      "Epoch 203/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0543 - val_loss: 0.0515\n",
      "Epoch 204/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0517 - val_loss: 0.0512\n",
      "Epoch 205/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0531 - val_loss: 0.0508\n",
      "Epoch 206/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0507 - val_loss: 0.0505\n",
      "Epoch 207/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0534 - val_loss: 0.0501\n",
      "Epoch 208/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0521 - val_loss: 0.0498\n",
      "Epoch 209/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0501 - val_loss: 0.0495\n",
      "Epoch 210/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0511 - val_loss: 0.0492\n",
      "Epoch 211/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0486 - val_loss: 0.0488\n",
      "Epoch 212/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0489 - val_loss: 0.0485\n",
      "Epoch 213/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0488 - val_loss: 0.0482\n",
      "Epoch 214/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0501 - val_loss: 0.0479\n",
      "Epoch 215/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0483 - val_loss: 0.0476\n",
      "Epoch 216/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0496 - val_loss: 0.0472\n",
      "Epoch 217/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0491 - val_loss: 0.0469\n",
      "Epoch 218/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0489 - val_loss: 0.0466\n",
      "Epoch 219/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0463 - val_loss: 0.0463\n",
      "Epoch 220/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0470 - val_loss: 0.0460\n",
      "Epoch 221/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0483 - val_loss: 0.0457\n",
      "Epoch 222/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0448 - val_loss: 0.0455\n",
      "Epoch 223/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0455 - val_loss: 0.0452\n",
      "Epoch 224/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0452 - val_loss: 0.0449\n",
      "Epoch 225/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0470 - val_loss: 0.0446\n",
      "Epoch 226/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0462 - val_loss: 0.0443\n",
      "Epoch 227/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0453 - val_loss: 0.0440\n",
      "Epoch 228/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0466 - val_loss: 0.0438\n",
      "Epoch 229/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0440 - val_loss: 0.0435\n",
      "Epoch 230/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0453 - val_loss: 0.0432\n",
      "Epoch 231/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0458 - val_loss: 0.0429\n",
      "Epoch 232/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0436 - val_loss: 0.0427\n",
      "Epoch 233/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0446 - val_loss: 0.0424\n",
      "Epoch 234/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0427 - val_loss: 0.0421\n",
      "Epoch 235/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0408 - val_loss: 0.0419\n",
      "Epoch 236/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0426 - val_loss: 0.0416\n",
      "Epoch 237/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0439 - val_loss: 0.0414\n",
      "Epoch 238/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0427 - val_loss: 0.0411\n",
      "Epoch 239/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0415 - val_loss: 0.0409\n",
      "Epoch 240/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0402 - val_loss: 0.0406\n",
      "Epoch 241/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0415 - val_loss: 0.0404\n",
      "Epoch 242/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0403 - val_loss: 0.0401\n",
      "Epoch 243/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0396 - val_loss: 0.0399\n",
      "Epoch 244/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0391 - val_loss: 0.0397\n",
      "Epoch 245/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0407 - val_loss: 0.0394\n",
      "Epoch 246/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0405 - val_loss: 0.0392\n",
      "Epoch 247/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0426 - val_loss: 0.0390\n",
      "Epoch 248/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0401 - val_loss: 0.0387\n",
      "Epoch 249/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0399 - val_loss: 0.0385\n",
      "Epoch 250/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0394 - val_loss: 0.0383\n",
      "Epoch 251/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0376 - val_loss: 0.0381\n",
      "Epoch 252/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0391 - val_loss: 0.0378\n",
      "Epoch 253/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0395 - val_loss: 0.0376\n",
      "Epoch 254/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0390 - val_loss: 0.0374\n",
      "Epoch 255/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0386 - val_loss: 0.0372\n",
      "Epoch 256/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0364 - val_loss: 0.0370\n",
      "Epoch 257/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0366 - val_loss: 0.0368\n",
      "Epoch 258/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0374 - val_loss: 0.0365\n",
      "Epoch 259/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0377 - val_loss: 0.0363\n",
      "Epoch 260/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0365 - val_loss: 0.0361\n",
      "Epoch 261/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0372 - val_loss: 0.0359\n",
      "Epoch 262/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0364 - val_loss: 0.0357\n",
      "Epoch 263/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 264/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0359 - val_loss: 0.0353\n",
      "Epoch 265/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0371 - val_loss: 0.0351\n",
      "Epoch 266/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0379 - val_loss: 0.0349\n",
      "Epoch 267/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0370 - val_loss: 0.0347\n",
      "Epoch 268/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.0346\n",
      "Epoch 269/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0348 - val_loss: 0.0344\n",
      "Epoch 270/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0349 - val_loss: 0.0342\n",
      "Epoch 271/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0341 - val_loss: 0.0340\n",
      "Epoch 272/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0342 - val_loss: 0.0338\n",
      "Epoch 273/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0367 - val_loss: 0.0336\n",
      "Epoch 274/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0334\n",
      "Epoch 275/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0341 - val_loss: 0.0333\n",
      "Epoch 276/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0347 - val_loss: 0.0331\n",
      "Epoch 277/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0329\n",
      "Epoch 278/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0321 - val_loss: 0.0327\n",
      "Epoch 279/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0326 - val_loss: 0.0326\n",
      "Epoch 280/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0324\n",
      "Epoch 281/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0308 - val_loss: 0.0322\n",
      "Epoch 282/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0320 - val_loss: 0.0320\n",
      "Epoch 283/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0321 - val_loss: 0.0319\n",
      "Epoch 284/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.0317\n",
      "Epoch 285/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0340 - val_loss: 0.0315\n",
      "Epoch 286/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0322 - val_loss: 0.0314\n",
      "Epoch 287/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0318 - val_loss: 0.0312\n",
      "Epoch 288/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0318 - val_loss: 0.0311\n",
      "Epoch 289/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0309\n",
      "Epoch 290/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0313 - val_loss: 0.0307\n",
      "Epoch 291/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0306 - val_loss: 0.0306\n",
      "Epoch 292/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0311 - val_loss: 0.0304\n",
      "Epoch 293/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0306 - val_loss: 0.0303\n",
      "Epoch 294/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: 0.0301\n",
      "Epoch 295/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0311 - val_loss: 0.0300\n",
      "Epoch 296/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.0298\n",
      "Epoch 297/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.0297\n",
      "Epoch 298/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0296 - val_loss: 0.0295\n",
      "Epoch 299/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0286 - val_loss: 0.0294\n",
      "Epoch 300/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.0292\n",
      "Epoch 301/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0297 - val_loss: 0.0291\n",
      "Epoch 302/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.0290\n",
      "Epoch 303/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.0288\n",
      "Epoch 304/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0293 - val_loss: 0.0287\n",
      "Epoch 305/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0285 - val_loss: 0.0285\n",
      "Epoch 306/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0276 - val_loss: 0.0284\n",
      "Epoch 307/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0284 - val_loss: 0.0283\n",
      "Epoch 308/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.0281\n",
      "Epoch 309/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0292 - val_loss: 0.0280\n",
      "Epoch 310/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0278 - val_loss: 0.0279\n",
      "Epoch 311/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0285 - val_loss: 0.0277\n",
      "Epoch 312/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0276\n",
      "Epoch 313/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0277 - val_loss: 0.0275\n",
      "Epoch 314/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0274\n",
      "Epoch 315/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0272\n",
      "Epoch 316/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0278 - val_loss: 0.0271\n",
      "Epoch 317/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0265 - val_loss: 0.0270\n",
      "Epoch 318/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0276 - val_loss: 0.0269\n",
      "Epoch 319/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0272 - val_loss: 0.0267\n",
      "Epoch 320/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0266\n",
      "Epoch 321/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0279 - val_loss: 0.0265\n",
      "Epoch 322/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0266 - val_loss: 0.0264\n",
      "Epoch 323/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0277 - val_loss: 0.0263\n",
      "Epoch 324/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0263 - val_loss: 0.0262\n",
      "Epoch 325/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0265 - val_loss: 0.0260\n",
      "Epoch 326/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0274 - val_loss: 0.0259\n",
      "Epoch 327/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0276 - val_loss: 0.0258\n",
      "Epoch 328/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0267 - val_loss: 0.0257\n",
      "Epoch 329/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0269 - val_loss: 0.0256\n",
      "Epoch 330/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0255\n",
      "Epoch 331/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0254\n",
      "Epoch 332/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0269 - val_loss: 0.0253\n",
      "Epoch 333/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0252\n",
      "Epoch 334/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0251\n",
      "Epoch 335/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0250\n",
      "Epoch 336/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0248\n",
      "Epoch 337/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0254 - val_loss: 0.0247\n",
      "Epoch 338/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0246\n",
      "Epoch 339/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0271 - val_loss: 0.0245\n",
      "Epoch 340/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0240 - val_loss: 0.0244\n",
      "Epoch 341/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0243\n",
      "Epoch 342/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0243\n",
      "Epoch 343/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0242\n",
      "Epoch 344/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0241\n",
      "Epoch 345/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0240\n",
      "Epoch 346/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0239\n",
      "Epoch 347/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0238\n",
      "Epoch 348/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0237\n",
      "Epoch 349/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0236\n",
      "Epoch 350/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0235\n",
      "Epoch 351/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0232 - val_loss: 0.0234\n",
      "Epoch 352/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0233\n",
      "Epoch 353/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0234 - val_loss: 0.0232\n",
      "Epoch 354/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0232\n",
      "Epoch 355/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0231\n",
      "Epoch 356/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0230\n",
      "Epoch 357/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0240 - val_loss: 0.0229\n",
      "Epoch 358/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0224 - val_loss: 0.0228\n",
      "Epoch 359/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.0227\n",
      "Epoch 360/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0225 - val_loss: 0.0227\n",
      "Epoch 361/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0234 - val_loss: 0.0226\n",
      "Epoch 362/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0225\n",
      "Epoch 363/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0225 - val_loss: 0.0224\n",
      "Epoch 364/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0224\n",
      "Epoch 365/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0236 - val_loss: 0.0223\n",
      "Epoch 366/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0222\n",
      "Epoch 367/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.0221\n",
      "Epoch 368/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0221\n",
      "Epoch 369/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.0220\n",
      "Epoch 370/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0223 - val_loss: 0.0219\n",
      "Epoch 371/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0231 - val_loss: 0.0218\n",
      "Epoch 372/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0218\n",
      "Epoch 373/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0225 - val_loss: 0.0217\n",
      "Epoch 374/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0218 - val_loss: 0.0216\n",
      "Epoch 375/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0216\n",
      "Epoch 376/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0213 - val_loss: 0.0215\n",
      "Epoch 377/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0225 - val_loss: 0.0214\n",
      "Epoch 378/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0221 - val_loss: 0.0214\n",
      "Epoch 379/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0223 - val_loss: 0.0213\n",
      "Epoch 380/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0218 - val_loss: 0.0212\n",
      "Epoch 381/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0212\n",
      "Epoch 382/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0211\n",
      "Epoch 383/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0216 - val_loss: 0.0211\n",
      "Epoch 384/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0210\n",
      "Epoch 385/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0211 - val_loss: 0.0209\n",
      "Epoch 386/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0208 - val_loss: 0.0209\n",
      "Epoch 387/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 388/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 389/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0222 - val_loss: 0.0207\n",
      "Epoch 390/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0221 - val_loss: 0.0206\n",
      "Epoch 391/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0216 - val_loss: 0.0206\n",
      "Epoch 392/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0208 - val_loss: 0.0205\n",
      "Epoch 393/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0219 - val_loss: 0.0205\n",
      "Epoch 394/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0218 - val_loss: 0.0204\n",
      "Epoch 395/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 396/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0211 - val_loss: 0.0203\n",
      "Epoch 397/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0209 - val_loss: 0.0203\n",
      "Epoch 398/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0210 - val_loss: 0.0202\n",
      "Epoch 399/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0199 - val_loss: 0.0202\n",
      "Epoch 400/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0212 - val_loss: 0.0201\n",
      "Epoch 401/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0222 - val_loss: 0.0201\n",
      "Epoch 402/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0208 - val_loss: 0.0200\n",
      "Epoch 403/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0210 - val_loss: 0.0200\n",
      "Epoch 404/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0215 - val_loss: 0.0199\n",
      "Epoch 405/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0203 - val_loss: 0.0199\n",
      "Epoch 406/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0199 - val_loss: 0.0198\n",
      "Epoch 407/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 408/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0206 - val_loss: 0.0197\n",
      "Epoch 409/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0223 - val_loss: 0.0197\n",
      "Epoch 410/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0207 - val_loss: 0.0196\n",
      "Epoch 411/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0196\n",
      "Epoch 412/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0205 - val_loss: 0.0196\n",
      "Epoch 413/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0206 - val_loss: 0.0195\n",
      "Epoch 414/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0209 - val_loss: 0.0195\n",
      "Epoch 415/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0213 - val_loss: 0.0194\n",
      "Epoch 416/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 417/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0193\n",
      "Epoch 418/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0199 - val_loss: 0.0193\n",
      "Epoch 419/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0202 - val_loss: 0.0193\n",
      "Epoch 420/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - val_loss: 0.0192\n",
      "Epoch 421/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0202 - val_loss: 0.0192\n",
      "Epoch 422/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0202 - val_loss: 0.0192\n",
      "Epoch 423/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0203 - val_loss: 0.0191\n",
      "Epoch 424/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - val_loss: 0.0191\n",
      "Epoch 425/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0205 - val_loss: 0.0190\n",
      "Epoch 426/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0199 - val_loss: 0.0190\n",
      "Epoch 427/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0209 - val_loss: 0.0190\n",
      "Epoch 428/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0189\n",
      "Epoch 429/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0200 - val_loss: 0.0189\n",
      "Epoch 430/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0198 - val_loss: 0.0189\n",
      "Epoch 431/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0188\n",
      "Epoch 432/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0188\n",
      "Epoch 433/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0198 - val_loss: 0.0188\n",
      "Epoch 434/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0187\n",
      "Epoch 435/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - val_loss: 0.0187\n",
      "Epoch 436/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0198 - val_loss: 0.0187\n",
      "Epoch 437/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0209 - val_loss: 0.0187\n",
      "Epoch 438/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0201 - val_loss: 0.0186\n",
      "Epoch 439/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0186\n",
      "Epoch 440/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - val_loss: 0.0186\n",
      "Epoch 441/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0185\n",
      "Epoch 442/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0195 - val_loss: 0.0185\n",
      "Epoch 443/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0185\n",
      "Epoch 444/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0185\n",
      "Epoch 445/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0192 - val_loss: 0.0184\n",
      "Epoch 446/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0184\n",
      "Epoch 447/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0198 - val_loss: 0.0184\n",
      "Epoch 448/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0184\n",
      "Epoch 449/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0183\n",
      "Epoch 450/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0191 - val_loss: 0.0183\n",
      "Epoch 451/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0197 - val_loss: 0.0183\n",
      "Epoch 452/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0183\n",
      "Epoch 453/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - val_loss: 0.0182\n",
      "Epoch 454/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0199 - val_loss: 0.0182\n",
      "Epoch 455/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0182\n",
      "Epoch 456/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - val_loss: 0.0182\n",
      "Epoch 457/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0196 - val_loss: 0.0181\n",
      "Epoch 458/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0181\n",
      "Epoch 459/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0192 - val_loss: 0.0181\n",
      "Epoch 460/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - val_loss: 0.0181\n",
      "Epoch 461/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0181\n",
      "Epoch 462/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0180\n",
      "Epoch 463/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0180\n",
      "Epoch 464/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0173 - val_loss: 0.0180\n",
      "Epoch 465/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0180\n",
      "Epoch 466/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0180\n",
      "Epoch 467/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0179\n",
      "Epoch 468/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0179\n",
      "Epoch 469/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - val_loss: 0.0179\n",
      "Epoch 470/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0179\n",
      "Epoch 471/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0179\n",
      "Epoch 472/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - val_loss: 0.0179\n",
      "Epoch 473/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0178\n",
      "Epoch 474/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - val_loss: 0.0178\n",
      "Epoch 475/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - val_loss: 0.0178\n",
      "Epoch 476/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0178\n",
      "Epoch 477/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0178\n",
      "Epoch 478/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0178\n",
      "Epoch 479/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0177\n",
      "Epoch 480/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0177\n",
      "Epoch 481/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0177\n",
      "Epoch 482/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - val_loss: 0.0177\n",
      "Epoch 483/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0177\n",
      "Epoch 484/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0177\n",
      "Epoch 485/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0177\n",
      "Epoch 486/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0177\n",
      "Epoch 487/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0176\n",
      "Epoch 488/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0176\n",
      "Epoch 489/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0179 - val_loss: 0.0176\n",
      "Epoch 490/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0176\n",
      "Epoch 491/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - val_loss: 0.0176\n",
      "Epoch 492/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0176\n",
      "Epoch 493/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0176\n",
      "Epoch 494/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0176\n",
      "Epoch 495/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0176\n",
      "Epoch 496/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0175\n",
      "Epoch 497/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0175\n",
      "Epoch 498/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0175\n",
      "Epoch 499/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - val_loss: 0.0175\n",
      "Epoch 500/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 501/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0175\n",
      "Epoch 502/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - val_loss: 0.0175\n",
      "Epoch 503/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0175\n",
      "Epoch 504/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0175\n",
      "Epoch 505/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0175\n",
      "Epoch 506/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0175\n",
      "Epoch 507/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0180 - val_loss: 0.0174\n",
      "Epoch 508/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0174\n",
      "Epoch 509/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0174\n",
      "Epoch 510/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 511/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0174\n",
      "Epoch 512/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0174\n",
      "Epoch 513/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0174\n",
      "Epoch 514/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0174\n",
      "Epoch 515/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0174\n",
      "Epoch 516/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0174\n",
      "Epoch 517/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - val_loss: 0.0174\n",
      "Epoch 518/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0174\n",
      "Epoch 519/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0174\n",
      "Epoch 520/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - val_loss: 0.0173\n",
      "Epoch 521/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0173 - val_loss: 0.0173\n",
      "Epoch 522/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0173\n",
      "Epoch 523/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - val_loss: 0.0173\n",
      "Epoch 524/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - val_loss: 0.0173\n",
      "Epoch 525/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0173\n",
      "Epoch 526/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - val_loss: 0.0173\n",
      "Epoch 527/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0173\n",
      "Epoch 528/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - val_loss: 0.0173\n",
      "Epoch 529/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0173\n",
      "Epoch 530/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0173\n",
      "Epoch 531/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0173\n",
      "Epoch 532/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - val_loss: 0.0173\n",
      "Epoch 533/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0173\n",
      "Epoch 534/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0173\n",
      "Epoch 535/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0173\n",
      "Epoch 536/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0173\n",
      "Epoch 537/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0173\n",
      "Epoch 538/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0167 - val_loss: 0.0173\n",
      "Epoch 539/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0166 - val_loss: 0.0172\n",
      "Epoch 540/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 541/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 542/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0172\n",
      "Epoch 543/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 544/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - val_loss: 0.0172\n",
      "Epoch 545/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - val_loss: 0.0172\n",
      "Epoch 546/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 547/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 548/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 549/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0172\n",
      "Epoch 550/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 551/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0172\n",
      "Epoch 552/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 553/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 554/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0172\n",
      "Epoch 555/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 556/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - val_loss: 0.0172\n",
      "Epoch 557/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 558/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0165 - val_loss: 0.0172\n",
      "Epoch 559/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 560/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 561/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0172\n",
      "Epoch 562/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - val_loss: 0.0172\n",
      "Epoch 563/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 564/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 565/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0167 - val_loss: 0.0172\n",
      "Epoch 566/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 567/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0172\n",
      "Epoch 568/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 569/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0172\n",
      "Epoch 570/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0172\n",
      "Epoch 571/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 572/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 573/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 574/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 575/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0172\n",
      "Epoch 576/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0190 - val_loss: 0.0172\n",
      "Epoch 577/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 578/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0172\n",
      "Epoch 579/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 580/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - val_loss: 0.0172\n",
      "Epoch 581/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 582/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 583/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0172\n",
      "Epoch 584/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - val_loss: 0.0172\n",
      "Epoch 585/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 586/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0172\n",
      "Epoch 587/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0171\n",
      "Epoch 588/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 589/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 590/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0171\n",
      "Epoch 591/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 592/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - val_loss: 0.0171\n",
      "Epoch 593/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 594/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 595/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 596/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 597/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - val_loss: 0.0171\n",
      "Epoch 598/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0171\n",
      "Epoch 599/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 600/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0171\n",
      "Epoch 601/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 602/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 603/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 604/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0171\n",
      "Epoch 605/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 606/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 607/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 608/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0175 - val_loss: 0.0171\n",
      "Epoch 609/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 610/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 611/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0171\n",
      "Epoch 612/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 613/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 614/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 615/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 616/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0183 - val_loss: 0.0171\n",
      "Epoch 617/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0171\n",
      "Epoch 618/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 619/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 620/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0171\n",
      "Epoch 621/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 622/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 623/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0171\n",
      "Epoch 624/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 625/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 626/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 627/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0171\n",
      "Epoch 628/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 629/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - val_loss: 0.0171\n",
      "Epoch 630/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 631/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0171\n",
      "Epoch 632/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 633/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0175 - val_loss: 0.0171\n",
      "Epoch 634/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0171\n",
      "Epoch 635/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 636/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 637/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 638/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 639/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 640/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 641/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0171\n",
      "Epoch 642/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0171\n",
      "Epoch 643/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0171\n",
      "Epoch 644/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0171\n",
      "Epoch 645/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0173 - val_loss: 0.0171\n",
      "Epoch 646/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 647/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 648/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0171\n",
      "Epoch 649/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 650/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 651/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0171\n",
      "Epoch 652/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0171\n",
      "Epoch 653/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0171\n",
      "Epoch 654/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0171\n",
      "Epoch 655/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0171\n",
      "Epoch 656/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0171\n",
      "Epoch 657/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0167 - val_loss: 0.0171\n",
      "Epoch 658/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0171\n",
      "Epoch 659/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0171\n",
      "Epoch 660/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0186 - val_loss: 0.0171\n",
      "Epoch 661/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 662/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0171\n",
      "Epoch 663/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 664/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 665/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 666/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0171\n",
      "Epoch 667/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 668/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 669/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 670/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 671/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0171\n",
      "Epoch 672/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0171\n",
      "Epoch 673/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 674/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 675/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0171\n",
      "Epoch 676/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 677/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 678/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0166 - val_loss: 0.0171\n",
      "Epoch 679/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 680/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 681/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0184 - val_loss: 0.0171\n",
      "Epoch 682/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 683/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0171\n",
      "Epoch 684/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 685/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0171\n",
      "Epoch 686/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0171\n",
      "Epoch 687/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0171\n",
      "Epoch 688/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 689/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 690/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 691/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 692/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0166 - val_loss: 0.0171\n",
      "Epoch 693/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0171\n",
      "Epoch 694/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 695/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 696/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 697/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 698/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - val_loss: 0.0171\n",
      "Epoch 699/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0171\n",
      "Epoch 700/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0171\n",
      "Epoch 701/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0171\n",
      "Epoch 702/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 703/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 704/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 705/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0183 - val_loss: 0.0171\n",
      "Epoch 706/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0171\n",
      "Epoch 707/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 708/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 709/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 710/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 711/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 712/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 713/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 714/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 715/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0171\n",
      "Epoch 716/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 717/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 718/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0171\n",
      "Epoch 719/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 720/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 721/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 722/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 723/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 724/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0171\n",
      "Epoch 725/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 726/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 727/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 728/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0171\n",
      "Epoch 729/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 730/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 731/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0171\n",
      "Epoch 732/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 733/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0173 - val_loss: 0.0171\n",
      "Epoch 734/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 735/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 736/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 737/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - val_loss: 0.0171\n",
      "Epoch 738/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 739/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 740/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 741/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0171\n",
      "Epoch 742/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 743/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 744/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 745/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0166 - val_loss: 0.0171\n",
      "Epoch 746/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 747/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0175 - val_loss: 0.0171\n",
      "Epoch 748/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 749/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 750/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0171\n",
      "Epoch 751/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 752/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 753/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0171\n",
      "Epoch 754/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 755/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0171\n",
      "Epoch 756/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 757/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 758/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 759/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0171\n",
      "Epoch 760/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0171\n",
      "Epoch 761/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0171\n",
      "Epoch 762/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 763/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 764/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0171\n",
      "Epoch 765/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 766/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 767/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0171\n",
      "Epoch 768/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 769/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - val_loss: 0.0171\n",
      "Epoch 770/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 771/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 772/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 773/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 774/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 775/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0171\n",
      "Epoch 776/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0171\n",
      "Epoch 777/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0167 - val_loss: 0.0171\n",
      "Epoch 778/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 779/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 780/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 781/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 782/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 783/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 784/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0195 - val_loss: 0.0171\n",
      "Epoch 785/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0171\n",
      "Epoch 786/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0171\n",
      "Epoch 787/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 788/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0171\n",
      "Epoch 789/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0171\n",
      "Epoch 790/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 791/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 792/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0171\n",
      "Epoch 793/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0171\n",
      "Epoch 794/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0171\n",
      "Epoch 795/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0166 - val_loss: 0.0171\n",
      "Epoch 796/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 797/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 798/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 799/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0171\n",
      "Epoch 800/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 801/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0171\n",
      "Epoch 802/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0171\n",
      "Epoch 803/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 804/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 805/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0190 - val_loss: 0.0171\n",
      "Epoch 806/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 807/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 808/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 809/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0161 - val_loss: 0.0171\n",
      "Epoch 810/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 811/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0171\n",
      "Epoch 812/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 813/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0172\n",
      "Epoch 814/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 815/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0172\n",
      "Epoch 816/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 817/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0172\n",
      "Epoch 818/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 819/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 820/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 821/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 822/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0171\n",
      "Epoch 823/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 824/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 825/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 826/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 827/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 828/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0172\n",
      "Epoch 829/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 830/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0166 - val_loss: 0.0172\n",
      "Epoch 831/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0172\n",
      "Epoch 832/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 833/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0172\n",
      "Epoch 834/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 835/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 836/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 837/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 838/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 839/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 840/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 841/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0172\n",
      "Epoch 842/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 843/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 844/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0166 - val_loss: 0.0172\n",
      "Epoch 845/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0172\n",
      "Epoch 846/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 847/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 848/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 849/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 850/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 851/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 852/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 853/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 854/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0172\n",
      "Epoch 855/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 856/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 857/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0172\n",
      "Epoch 858/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 859/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 860/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0172\n",
      "Epoch 861/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0172\n",
      "Epoch 862/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 863/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 864/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 865/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 866/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 867/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 868/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0172\n",
      "Epoch 869/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0172\n",
      "Epoch 870/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 871/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 872/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 873/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0186 - val_loss: 0.0172\n",
      "Epoch 874/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 875/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 876/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 877/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 878/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 879/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 880/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 881/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 882/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 883/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 884/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 885/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0172\n",
      "Epoch 886/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 887/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 888/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 889/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 890/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 891/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0172\n",
      "Epoch 892/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 893/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 894/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 895/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 896/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 897/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0172\n",
      "Epoch 898/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 899/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 900/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 901/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 902/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 903/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0172\n",
      "Epoch 904/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0172\n",
      "Epoch 905/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 906/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 907/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0172\n",
      "Epoch 908/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0172\n",
      "Epoch 909/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 910/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 911/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0172\n",
      "Epoch 912/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 913/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0172\n",
      "Epoch 914/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 915/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0172\n",
      "Epoch 916/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 917/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 918/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 919/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0167 - val_loss: 0.0172\n",
      "Epoch 920/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0172\n",
      "Epoch 921/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 922/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 923/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 924/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 925/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0172\n",
      "Epoch 926/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - val_loss: 0.0172\n",
      "Epoch 927/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 928/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 929/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 930/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 931/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 932/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0172\n",
      "Epoch 933/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0192 - val_loss: 0.0172\n",
      "Epoch 934/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 935/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 936/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 937/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 938/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0172\n",
      "Epoch 939/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 940/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 941/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 942/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 943/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 944/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0167 - val_loss: 0.0172\n",
      "Epoch 945/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0172\n",
      "Epoch 946/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 947/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 948/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 949/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 950/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 951/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0172\n",
      "Epoch 952/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 953/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 954/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 955/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 956/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 957/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 958/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0172\n",
      "Epoch 959/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 960/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0172\n",
      "Epoch 961/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 962/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 963/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0172\n",
      "Epoch 964/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 965/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 966/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 967/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 968/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0167 - val_loss: 0.0172\n",
      "Epoch 969/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0172\n",
      "Epoch 970/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 971/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 972/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - val_loss: 0.0172\n",
      "Epoch 973/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 974/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 975/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 976/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0162 - val_loss: 0.0172\n",
      "Epoch 977/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 978/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 979/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 980/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 981/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0172\n",
      "Epoch 982/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 983/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 984/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 985/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0172\n",
      "Epoch 986/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 987/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0163 - val_loss: 0.0172\n",
      "Epoch 988/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0172\n",
      "Epoch 989/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 990/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0165 - val_loss: 0.0172\n",
      "Epoch 991/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 992/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 993/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - val_loss: 0.0172\n",
      "Epoch 994/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 995/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 996/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 997/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 998/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 999/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 1000/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0172\n"
     ]
    }
   ],
   "source": [
    "#opt = keras.optimizers.SGD(learning_rate=MY_LEARNING_RATE)\n",
    "opt = keras.optimizers.Adam(learning_rate=MY_LEARNING_RATE)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=opt)\n",
    "history = model.fit(X_train_scaled, y_train_scaled, epochs=MY_EPOCHS, batch_size=MY_BATCH_SIZE,\n",
    "                    validation_data=(X_valid_scaled, y_valid_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4df21ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curves\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "#plt.gca().set_ylim(0, 5e-4) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb432acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 0.0186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13175923977487936"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test_scaled, y_test_scaled)\n",
    "np.sqrt(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "181daa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test_scaled[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca87781a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70387156],\n",
       "       [0.46099428],\n",
       "       [0.14043717]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_scaled[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d8a8fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44172606],\n",
       "       [0.43740255],\n",
       "       [0.45245737]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d0bc8",
   "metadata": {},
   "source": [
    "# Fine-Tuning Neural Network Hyperparameters\n",
    "\n",
    "Wrap our Keras models in objects that mimic regular Scikit-Learn regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e052ee1",
   "metadata": {},
   "source": [
    "def build_model(n_hidden, n_neurons, learning_rate, \n",
    "                input_shape):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", \n",
    "                                     **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, **options))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "keras_reg = KerasRegressor(build_model, n_hidden=1, n_neurons=30, learning_rate=3e-3, \n",
    "                input_shape=[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "8a171888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    #model.add(layers.Flatten())\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 5)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "               # Tune number of units separately for each layer.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                activation=\"relu\",\n",
    "            )\n",
    "        )\n",
    "    model.add(layers.Dense(1))\n",
    "    #learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        #optimizer=keras.optimizers.SGD(learning_rate=MY_LEARNING_RATE),\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=MY_LEARNING_RATE),\n",
    "        #optimizer=MY_OPTIMIZER,\n",
    "        loss=\"mean_squared_error\",\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "537260cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential_2, built=False>"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quickly test if model builds successfuly\n",
    "import keras_tuner\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894b3759",
   "metadata": {},
   "source": [
    "Use a randomized search to train hundreds of hyperparameter combinations  and see which one performs best on the validation set.\n",
    "\n",
    "Note that RandomizedSearchCV uses K-fold cross-validation, so it\n",
    "does not use X_valid and y_valid_scaled . These are just used for early stopping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf98fb",
   "metadata": {},
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, \n",
    "                                   n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train_scaled, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid_scaled),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "46016dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "04174a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# print a summary of the search space\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dac7ce",
   "metadata": {},
   "source": [
    "Then, start the search for the best hyperparameter configuration. All the arguments passed to search is passed to model.fit() in each execution. Remember to pass validation_data to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "2b9dc4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "2                 |2                 |num_layers\n",
      "512               |512               |units_0\n",
      "\n",
      "Epoch 1/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0527 - val_loss: 0.0625\n",
      "Epoch 2/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0526 - val_loss: 0.0618\n",
      "Epoch 3/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0513 - val_loss: 0.0612\n",
      "Epoch 4/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0508 - val_loss: 0.0606\n",
      "Epoch 5/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0509 - val_loss: 0.0600\n",
      "Epoch 6/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0506 - val_loss: 0.0594\n",
      "Epoch 7/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0495 - val_loss: 0.0588\n",
      "Epoch 8/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0484 - val_loss: 0.0582\n",
      "Epoch 9/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0486 - val_loss: 0.0576\n",
      "Epoch 10/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0479 - val_loss: 0.0570\n",
      "Epoch 11/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0475 - val_loss: 0.0565\n",
      "Epoch 12/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0465 - val_loss: 0.0559\n",
      "Epoch 13/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0462 - val_loss: 0.0553\n",
      "Epoch 14/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0458 - val_loss: 0.0548\n",
      "Epoch 15/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0450 - val_loss: 0.0543\n",
      "Epoch 16/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0448 - val_loss: 0.0537\n",
      "Epoch 17/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0441 - val_loss: 0.0532\n",
      "Epoch 18/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0440 - val_loss: 0.0527\n",
      "Epoch 19/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0428 - val_loss: 0.0522\n",
      "Epoch 20/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0422 - val_loss: 0.0517\n",
      "Epoch 21/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0420 - val_loss: 0.0512\n",
      "Epoch 22/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0419 - val_loss: 0.0507\n",
      "Epoch 23/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0416 - val_loss: 0.0502\n",
      "Epoch 24/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0410 - val_loss: 0.0497\n",
      "Epoch 25/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0411 - val_loss: 0.0492\n",
      "Epoch 26/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0409 - val_loss: 0.0488\n",
      "Epoch 27/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0397 - val_loss: 0.0483\n",
      "Epoch 28/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0396 - val_loss: 0.0478\n",
      "Epoch 29/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0393 - val_loss: 0.0474\n",
      "Epoch 30/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0391 - val_loss: 0.0469\n",
      "Epoch 31/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0386 - val_loss: 0.0465\n",
      "Epoch 32/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0383 - val_loss: 0.0460\n",
      "Epoch 33/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0372 - val_loss: 0.0456\n",
      "Epoch 34/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0377 - val_loss: 0.0452\n",
      "Epoch 35/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0364 - val_loss: 0.0447\n",
      "Epoch 36/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0362 - val_loss: 0.0443\n",
      "Epoch 37/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0355 - val_loss: 0.0439\n",
      "Epoch 38/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0356 - val_loss: 0.0435\n",
      "Epoch 39/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0352 - val_loss: 0.0431\n",
      "Epoch 40/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0349 - val_loss: 0.0427\n",
      "Epoch 41/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0349 - val_loss: 0.0424\n",
      "Epoch 42/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0350 - val_loss: 0.0420\n",
      "Epoch 43/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0344 - val_loss: 0.0416\n",
      "Epoch 44/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0331 - val_loss: 0.0412\n",
      "Epoch 45/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0335 - val_loss: 0.0409\n",
      "Epoch 46/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0329 - val_loss: 0.0405\n",
      "Epoch 47/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0326 - val_loss: 0.0402\n",
      "Epoch 48/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0324 - val_loss: 0.0398\n",
      "Epoch 49/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0324 - val_loss: 0.0395\n",
      "Epoch 50/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0315 - val_loss: 0.0391\n",
      "Epoch 51/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0315 - val_loss: 0.0388\n",
      "Epoch 52/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0311 - val_loss: 0.0385\n",
      "Epoch 53/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0312 - val_loss: 0.0382\n",
      "Epoch 54/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0309 - val_loss: 0.0378\n",
      "Epoch 55/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0302 - val_loss: 0.0375\n",
      "Epoch 56/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0305 - val_loss: 0.0372\n",
      "Epoch 57/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0298 - val_loss: 0.0369\n",
      "Epoch 58/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0299 - val_loss: 0.0366\n",
      "Epoch 59/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0296 - val_loss: 0.0363\n",
      "Epoch 60/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0291 - val_loss: 0.0360\n",
      "Epoch 61/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0288 - val_loss: 0.0357\n",
      "Epoch 62/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0292 - val_loss: 0.0354\n",
      "Epoch 63/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0284 - val_loss: 0.0351\n",
      "Epoch 64/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0283 - val_loss: 0.0348\n",
      "Epoch 65/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0284 - val_loss: 0.0345\n",
      "Epoch 66/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0277 - val_loss: 0.0343\n",
      "Epoch 67/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0277 - val_loss: 0.0340\n",
      "Epoch 68/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0271 - val_loss: 0.0338\n",
      "Epoch 69/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0270 - val_loss: 0.0335\n",
      "Epoch 70/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0268 - val_loss: 0.0332\n",
      "Epoch 71/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0265 - val_loss: 0.0330\n",
      "Epoch 72/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0264 - val_loss: 0.0328\n",
      "Epoch 73/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0260 - val_loss: 0.0325\n",
      "Epoch 74/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0257 - val_loss: 0.0323\n",
      "Epoch 75/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0260 - val_loss: 0.0320\n",
      "Epoch 76/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0254 - val_loss: 0.0318\n",
      "Epoch 77/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0253 - val_loss: 0.0316\n",
      "Epoch 78/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0255 - val_loss: 0.0314\n",
      "Epoch 79/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0250 - val_loss: 0.0311\n",
      "Epoch 80/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0248 - val_loss: 0.0309\n",
      "Epoch 81/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0248 - val_loss: 0.0307\n",
      "Epoch 82/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0250 - val_loss: 0.0305\n",
      "Epoch 83/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0246 - val_loss: 0.0303\n",
      "Epoch 84/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0241 - val_loss: 0.0301\n",
      "Epoch 85/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0239 - val_loss: 0.0299\n",
      "Epoch 86/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0237 - val_loss: 0.0297\n",
      "Epoch 87/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0239 - val_loss: 0.0295\n",
      "Epoch 88/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0235 - val_loss: 0.0293\n",
      "Epoch 89/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0237 - val_loss: 0.0292\n",
      "Epoch 90/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0235 - val_loss: 0.0290\n",
      "Epoch 91/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0232 - val_loss: 0.0288\n",
      "Epoch 92/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0232 - val_loss: 0.0286\n",
      "Epoch 93/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0231 - val_loss: 0.0284\n",
      "Epoch 94/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0230 - val_loss: 0.0283\n",
      "Epoch 95/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0226 - val_loss: 0.0281\n",
      "Epoch 96/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0222 - val_loss: 0.0279\n",
      "Epoch 97/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0224 - val_loss: 0.0278\n",
      "Epoch 98/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0222 - val_loss: 0.0276\n",
      "Epoch 99/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0223 - val_loss: 0.0274\n",
      "Epoch 100/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0221 - val_loss: 0.0273\n",
      "Epoch 101/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0219 - val_loss: 0.0271\n",
      "Epoch 102/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0217 - val_loss: 0.0270\n",
      "Epoch 103/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0219 - val_loss: 0.0268\n",
      "Epoch 104/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0216 - val_loss: 0.0267\n",
      "Epoch 105/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0214 - val_loss: 0.0265\n",
      "Epoch 106/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0212 - val_loss: 0.0264\n",
      "Epoch 107/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0211 - val_loss: 0.0263\n",
      "Epoch 108/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0212 - val_loss: 0.0261\n",
      "Epoch 109/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0209 - val_loss: 0.0260\n",
      "Epoch 110/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0208 - val_loss: 0.0259\n",
      "Epoch 111/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0208 - val_loss: 0.0257\n",
      "Epoch 112/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0207 - val_loss: 0.0256\n",
      "Epoch 113/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0206 - val_loss: 0.0255\n",
      "Epoch 114/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0204 - val_loss: 0.0253\n",
      "Epoch 115/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0203 - val_loss: 0.0252\n",
      "Epoch 116/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0206 - val_loss: 0.0251\n",
      "Epoch 117/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0207 - val_loss: 0.0250\n",
      "Epoch 118/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0201 - val_loss: 0.0249\n",
      "Epoch 119/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0202 - val_loss: 0.0248\n",
      "Epoch 120/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0202 - val_loss: 0.0247\n",
      "Epoch 121/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0200 - val_loss: 0.0246\n",
      "Epoch 122/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0200 - val_loss: 0.0244\n",
      "Epoch 123/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0197 - val_loss: 0.0243\n",
      "Epoch 124/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0197 - val_loss: 0.0242\n",
      "Epoch 125/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0199 - val_loss: 0.0241\n",
      "Epoch 126/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0197 - val_loss: 0.0241\n",
      "Epoch 127/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0199 - val_loss: 0.0240\n",
      "Epoch 128/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0197 - val_loss: 0.0239\n",
      "Epoch 129/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0195 - val_loss: 0.0238\n",
      "Epoch 130/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0194 - val_loss: 0.0237\n",
      "Epoch 131/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0196 - val_loss: 0.0236\n",
      "Epoch 132/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0194 - val_loss: 0.0235\n",
      "Epoch 133/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0194 - val_loss: 0.0234\n",
      "Epoch 134/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0190 - val_loss: 0.0234\n",
      "Epoch 135/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0192 - val_loss: 0.0233\n",
      "Epoch 136/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0191 - val_loss: 0.0232\n",
      "Epoch 137/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0191 - val_loss: 0.0231\n",
      "Epoch 138/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0191 - val_loss: 0.0230\n",
      "Epoch 139/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0187 - val_loss: 0.0230\n",
      "Epoch 140/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0194 - val_loss: 0.0229\n",
      "Epoch 141/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0188 - val_loss: 0.0228\n",
      "Epoch 142/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0187 - val_loss: 0.0227\n",
      "Epoch 143/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0188 - val_loss: 0.0227\n",
      "Epoch 144/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0188 - val_loss: 0.0226\n",
      "Epoch 145/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0190 - val_loss: 0.0225\n",
      "Epoch 146/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0193 - val_loss: 0.0225\n",
      "Epoch 147/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0186 - val_loss: 0.0224\n",
      "Epoch 148/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0185 - val_loss: 0.0223\n",
      "Epoch 149/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0183 - val_loss: 0.0223\n",
      "Epoch 150/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0186 - val_loss: 0.0222\n",
      "Epoch 151/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0186 - val_loss: 0.0222\n",
      "Epoch 152/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0186 - val_loss: 0.0221\n",
      "Epoch 153/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0186 - val_loss: 0.0220\n",
      "Epoch 154/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0185 - val_loss: 0.0220\n",
      "Epoch 155/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0182 - val_loss: 0.0219\n",
      "Epoch 156/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0185 - val_loss: 0.0219\n",
      "Epoch 157/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0182 - val_loss: 0.0218\n",
      "Epoch 158/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0179 - val_loss: 0.0218\n",
      "Epoch 159/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0182 - val_loss: 0.0217\n",
      "Epoch 160/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0180 - val_loss: 0.0217\n",
      "Epoch 161/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0181 - val_loss: 0.0216\n",
      "Epoch 162/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0181 - val_loss: 0.0216\n",
      "Epoch 163/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0183 - val_loss: 0.0215\n",
      "Epoch 164/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0177 - val_loss: 0.0215\n",
      "Epoch 165/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0183 - val_loss: 0.0215\n",
      "Epoch 166/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0179 - val_loss: 0.0214\n",
      "Epoch 167/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0180 - val_loss: 0.0214\n",
      "Epoch 168/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0179 - val_loss: 0.0213\n",
      "Epoch 169/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0182 - val_loss: 0.0213\n",
      "Epoch 170/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0181 - val_loss: 0.0213\n",
      "Epoch 171/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0177 - val_loss: 0.0212\n",
      "Epoch 172/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0185 - val_loss: 0.0212\n",
      "Epoch 173/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0182 - val_loss: 0.0212\n",
      "Epoch 174/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0177 - val_loss: 0.0211\n",
      "Epoch 175/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0180 - val_loss: 0.0211\n",
      "Epoch 176/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0181 - val_loss: 0.0211\n",
      "Epoch 177/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0179 - val_loss: 0.0210\n",
      "Epoch 178/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0176 - val_loss: 0.0210\n",
      "Epoch 179/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0181 - val_loss: 0.0210\n",
      "Epoch 180/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0177 - val_loss: 0.0209\n",
      "Epoch 181/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0178 - val_loss: 0.0209\n",
      "Epoch 182/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0179 - val_loss: 0.0209\n",
      "Epoch 183/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0177 - val_loss: 0.0208\n",
      "Epoch 184/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0174 - val_loss: 0.0208\n",
      "Epoch 185/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0177 - val_loss: 0.0208\n",
      "Epoch 186/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0177 - val_loss: 0.0208\n",
      "Epoch 187/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0179 - val_loss: 0.0207\n",
      "Epoch 188/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0176 - val_loss: 0.0207\n",
      "Epoch 189/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0176 - val_loss: 0.0207\n",
      "Epoch 190/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0175 - val_loss: 0.0207\n",
      "Epoch 191/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[606], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch(X_train_scaled, y_train_scaled, epochs\u001b[38;5;241m=\u001b[39mMY_EPOCHS, batch_size\u001b[38;5;241m=\u001b[39mMY_BATCH_SIZE, validation_data\u001b[38;5;241m=\u001b[39m(X_valid_scaled, y_valid_scaled))\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:321\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    319\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    322\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m    323\u001b[0m         logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:654\u001b[0m, in \u001b[0;36mTFEpochIterator.enumerate_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 654\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distributed_dataset)\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches:\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\n\u001b[1;32m    657\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution\n\u001b[1;32m    658\u001b[0m         ):\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:501\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    500\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iterator_ops\u001b[38;5;241m.\u001b[39mOwnedIterator(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:705\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    701\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    704\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 705\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_iterator(dataset)\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:744\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    741\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    742\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[1;32m    743\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[0;32m--> 744\u001b[0m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmake_iterator(ds_variant, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource)\n",
      "File \u001b[0;32m~/anaconda3/envs/halo/lib/python3.12/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3478\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3477\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3478\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[1;32m   3479\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMakeIterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, dataset, iterator)\n\u001b[1;32m   3480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3481\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(X_train_scaled, y_train_scaled, epochs=MY_EPOCHS, batch_size=MY_BATCH_SIZE, validation_data=(X_valid_scaled, y_valid_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d5b759",
   "metadata": {},
   "source": [
    "## Query the results\n",
    "When search is over, you can retrieve the best model(s). The model is saved at its best performing epoch evaluated on the validation_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d995384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse_test = best_model.evaluate(X_test_scaled, y_test_scaled)\n",
    "np.sqrt(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9226c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test_scaled[:10] # pretend these are new instances\n",
    "y_pred = best_model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b7814",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_scaled[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc967704",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04410338",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(\"best_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:halo]",
   "language": "python",
   "name": "conda-env-halo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
